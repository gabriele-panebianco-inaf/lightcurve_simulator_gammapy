{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656375d9",
   "metadata": {},
   "source": [
    "# Create a Lightcurve Simulator in Gammapy-0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c697e4",
   "metadata": {},
   "source": [
    "## 0 - Setup: import packages of the environment gammapy-0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, PowerNorm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table, QTable, hstack\n",
    "from astropy.io import fits\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74044b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import Observation\n",
    "from gammapy.datasets import SpectrumDataset, Datasets, FluxPointsDataset\n",
    "from gammapy.estimators import LightCurveEstimator\n",
    "from gammapy.irf import (\n",
    "    EffectiveAreaTable2D,\n",
    "    Background2D, Background3D,\n",
    "    EnergyDispersion2D, EDispKernel, EDispKernelMap,\n",
    ")\n",
    "from gammapy.makers import SpectrumDatasetMaker\n",
    "from gammapy.maps import MapAxis, RegionGeom, TimeMapAxis\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    ExpCutoffPowerLawSpectralModel,\n",
    "    SkyModel,\n",
    "    LightCurveTemplateTemporalModel\n",
    ")\n",
    "from gammapy.utils.random import get_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd466cd5",
   "metadata": {},
   "source": [
    "Load BAK and RSP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRB 120323 A, FERMI-GBM, N0\n",
    "\n",
    "# Input files\n",
    "input_directory = \"/home/gabriele/Documents/fermiGBM/\"                                    # Define Data Directory\n",
    "file_bak = input_directory + \"Output/grb_120323_A/\"  + \"n0_10ms_10_900_keV.bak\"           # Define BAK file\n",
    "file_rsp = input_directory + \"FermiData/bn120323507/\"+ \"glg_cspec_n0_bn120323507_v01.rsp\" # Define RSP file\n",
    "\n",
    "# Energy ranges\n",
    "INTERP       = 'lin'     # Choose how to interpolate the energies # 'lin' or 'log'\n",
    "slice_energy = True      # Choose if you want to slice the energies and reduce the energy range\n",
    "custom_range_energy_reco = (8.0,  900.0) * u.keV # Choose boundaries for the energy range\n",
    "custom_range_energy_true = (5.5, 1000.0) * u.keV\n",
    "\n",
    "# Original GBM burst data and light curve best fit\n",
    "GBM_original_name = '/home/gabriele/Documents/fermiGBM/Output/grb_120323_A/'\n",
    "GBM_original_name+= 'n0_10ms_10_900_keV_fit_LC_table.fits'\n",
    "\n",
    "# Spectral fit time range and parameters\n",
    "# Fit: from scat file, GBM Team.\n",
    "# Detectors used: BGO00 [285,40108] keV, NAI00 & NAI3 [7,908] keV\n",
    "# Spectral model: Comptonized.\n",
    "# DRMs: original .rsp files.\n",
    "spectral_fit_time_range = [0.064, 0.128]\n",
    "GBM_Ampli =   1.12 *(u.cm**(-2) * u.s**(-1) * u.keV**(-1)) # Correction factor later\n",
    "GBM_Index = - 1.52 * u.Unit(\"\")\n",
    "GBM_Epeak = 413.79 * u.keV\n",
    "GBM_Erefe = 100.00 * u.keV\n",
    "\n",
    "# Observation Livetimes parameters: temporal binning of the light curve\n",
    "time_unit  = u.s\n",
    "t_start_obs=-0.305 * time_unit # Start time of the observations wrt to trigger time ref_t0\n",
    "t_stop_obs = 0.795 * time_unit # Stop time of the observations wrt to trigger time ref_t0\n",
    "live_t_obs = 0.010 * time_unit # Time duration of each observation\n",
    "dead_times = 0.000 * time_unit # Rest time between observations\n",
    "\n",
    "# Number of requested Light Curves\n",
    "Number_of_LightCurves = 15\n",
    "\n",
    "# Strings for plot of Light Curves\n",
    "title_name_transient = \"GRB120323A\"\n",
    "title_name_instrument= \"Fermi-GBM detector \"+ hdulist_rsp['PRIMARY'].header['DETNAM']\n",
    "title_name_prefix    = \"GBM_n0_10ms_10_900_keV_\"\n",
    "\n",
    "# Output directory and table filename\n",
    "output_directory= \"/home/gabriele/Documents/gammapy/LCsim/Output/GRB120323A/\"\n",
    "output_filename = output_directory + title_name_prefix + \"lightcurves.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRB 120323 A, FERMI-GBM, B0\n",
    "\n",
    "# Input files\n",
    "input_directory = \"/home/gabriele/Documents/fermiGBM/\"                                    # Define Data Directory\n",
    "file_bak = input_directory + \"Output/grb_120323_A/\"  + \"b0_15ms_250_40000_keV.bak\"        # Define BAK file\n",
    "file_rsp = input_directory + \"FermiData/bn120323507/\"+ \"glg_cspec_b0_bn120323507_v01.rsp\" # Define RSP file\n",
    "\n",
    "# Energy ranges\n",
    "INTERP       = 'log'     # Choose how to interpolate the energies # 'lin' or 'log'\n",
    "slice_energy = True      # Choose if you want to slice the energies and reduce the energy range\n",
    "custom_range_energy_reco = (250.0, 40000.0) * u.keV # Choose boundaries for the energy range\n",
    "custom_range_energy_true = (200.0, 50000.0) * u.keV\n",
    "\n",
    "# Original GBM burst data and light curve best fit\n",
    "GBM_original_name = '/home/gabriele/Documents/fermiGBM/Output/grb_120323_A/'\n",
    "GBM_original_name+= 'b0_15ms_250_40000_keV_fit_LC_table.fits'\n",
    "\n",
    "# Spectral fit time range and parameters\n",
    "# Fit: from scat file, GBM Team.\n",
    "# Detectors used: BGO00 [285,40108] keV, NAI00 & NAI3 [7,908] keV\n",
    "# Spectral model: Comptonized.\n",
    "# DRMs: original .rsp files.\n",
    "spectral_fit_time_range = [0.064, 0.128]\n",
    "GBM_Ampli = (1.12+0.03) *(u.cm**(-2) * u.s**(-1) * u.keV**(-1)) # Correction factor later\n",
    "GBM_Index = - (1.52-0.02) * u.Unit(\"\")\n",
    "GBM_Epeak = (413.79+37.) * u.keV\n",
    "GBM_Erefe = 100.00 * u.keV\n",
    "\n",
    "# Observation Livetimes parameters: temporal binning of the light curve\n",
    "time_unit  = u.s\n",
    "t_start_obs=-0.305 * time_unit # Start time of the observations wrt to trigger time ref_t0\n",
    "t_stop_obs = 0.795 * time_unit # Stop time of the observations wrt to trigger time ref_t0\n",
    "live_t_obs = 0.010 * time_unit # Time duration of each observation\n",
    "dead_times = 0.000 * time_unit # Rest time between observations\n",
    "\n",
    "# Number of requested Light Curves\n",
    "Number_of_LightCurves = 15\n",
    "\n",
    "# Strings for plot of Light Curves\n",
    "title_name_transient = \"GRB120323A\"\n",
    "title_name_instrument= \"Fermi-GBM detector BGO_00\"\n",
    "title_name_prefix    = \"GBM_b0_15ms_250_40000_keV_\"\n",
    "\n",
    "# Output directory and table filename\n",
    "output_directory= \"/home/gabriele/Documents/gammapy/LCsim/Output/GRB120323A/\"\n",
    "output_filename = output_directory + title_name_prefix + \"lightcurves.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524e726",
   "metadata": {},
   "source": [
    "## 1 - Load the Detector Response Matrix\n",
    "\n",
    "This file is used to define a Reference Time, a Pointing Direction, the True Energy Axis, the Reconstructed Energy Axis, the Detector Response Matrix, the Effective Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928eeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist_rsp = fits.open(file_rsp)\n",
    "\n",
    "# Print the Information and Primary Header\n",
    "print(hdulist_rsp.info())\n",
    "#hdulist_rsp['PRIMARY'].header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27034368",
   "metadata": {},
   "source": [
    "#### 1.1 - Define the Reference Time of the simulated observations as the Trigger Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78697071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trigger Time as the Reference Time of the simulated observations\n",
    "TIMESYS = hdulist_rsp['PRIMARY'].header['TIMESYS'].lower()\n",
    "\n",
    "trigger_time_t0 = hdulist_rsp['PRIMARY'].header['MJDREFI']\n",
    "trigger_time_t0+= hdulist_rsp['PRIMARY'].header['MJDREFF']\n",
    "trigger_time_t0+= hdulist_rsp['PRIMARY'].header['TRIGTIME'] / 86400.0\n",
    "\n",
    "trigger_time_t0 = Time(trigger_time_t0,\n",
    "                       format = 'mjd',\n",
    "                       scale = TIMESYS\n",
    "                      )\n",
    "\n",
    "# Define preferred time format\n",
    "TimeMapAxis.time_format = \"iso\" \n",
    "trigger_time_t0.format = TimeMapAxis.time_format\n",
    "\n",
    "# Print\n",
    "trigger_time_t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb675b4",
   "metadata": {},
   "source": [
    "#### 1.2 - Define the Pointing Direction of the simulated observations and the FoV (Lon, Lat, Offset) axes\n",
    "\n",
    "We must define a *pointing* direction.\n",
    "In IACTs this is very close to the target direction, in satellites it is very far in general for GRBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fe9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pointing Direction of the simulated instrument as the Object direction\n",
    "RA_OBJ  = hdulist_rsp['PRIMARY'].header['RA_OBJ' ]\n",
    "DEC_OBJ = hdulist_rsp['PRIMARY'].header['DEC_OBJ']\n",
    "FRAME   = hdulist_rsp['PRIMARY'].header['RADECSYS'].lower()\n",
    "\n",
    "pointing = SkyCoord(RA_OBJ,\n",
    "                    DEC_OBJ,\n",
    "                    unit = \"deg\",\n",
    "                    frame = FRAME\n",
    "                   )\n",
    "\n",
    "# Print\n",
    "pointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f509cc3",
   "metadata": {},
   "source": [
    "Define Instrument FoV Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: The FoV Center is (0,0), FoV_Lon and FoV_Lat are symmetric wrt to 0.0\n",
    "\n",
    "fov_maximum_offset = 20.0 * u.deg\n",
    "fov_n_bin = 20\n",
    "\n",
    "# Create Offset axis\n",
    "axis_offset = MapAxis.from_bounds(0.0,\n",
    "                                  fov_maximum_offset.value,\n",
    "                                  unit = fov_maximum_offset.unit,\n",
    "                                  nbin = fov_n_bin,\n",
    "                                  name = \"offset\"\n",
    "                                 )\n",
    "# Create Instrument FoV_lon axis\n",
    "axis_fovlon = MapAxis.from_bounds(-fov_maximum_offset.value/2.0,\n",
    "                                  +fov_maximum_offset.value/2.0,\n",
    "                                  unit = fov_maximum_offset.unit,\n",
    "                                  nbin = fov_n_bin,\n",
    "                                  name = \"fov_lon\"\n",
    "                                 )\n",
    "# Create Instrument FoV_lat axis\n",
    "axis_fovlat = MapAxis.from_bounds(-fov_maximum_offset.value/2.0,\n",
    "                                  +fov_maximum_offset.value/2.0,\n",
    "                                  unit = fov_maximum_offset.unit,\n",
    "                                  nbin = fov_n_bin,\n",
    "                                  name = \"fov_lat\"\n",
    "                                 )\n",
    "\n",
    "# Print\n",
    "print(axis_offset)\n",
    "print(axis_fovlon)\n",
    "print(axis_fovlat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ec7ac",
   "metadata": {},
   "source": [
    "#### 1.3 - Define the True and Reconstructed Energy Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8511a",
   "metadata": {},
   "source": [
    "Define the Reconstructed Energy Axis.\n",
    "\n",
    "This is done from the EBOUNDS hdu of the response file.\n",
    "This name might change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a870896",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebounds = hdulist_rsp['EBOUNDS'].header['EXTNAME']\n",
    "\n",
    "reco_table = Table.read( hdulist_rsp[ebounds] )\n",
    "\n",
    "reco_energy_min = reco_table[\"E_MIN\"].quantity\n",
    "reco_energy_max = reco_table[\"E_MAX\"].quantity\n",
    "\n",
    "# Define Edges\n",
    "reco_energy_edges = np.append(reco_energy_min.value, reco_energy_max.value[-1]) * reco_energy_min.unit\n",
    "\n",
    "# Define Axis\n",
    "axis_energy_reco = MapAxis.from_edges(reco_energy_edges,\n",
    "                                      name = \"energy\",\n",
    "                                      interp = INTERP\n",
    "                                     )\n",
    "\n",
    "# Slice by finding the clostes edges in the energy axis to the requested bounds.\n",
    "if slice_energy:\n",
    "    \n",
    "    range_message = 'Original energy range: [{}, {}] '.format(np.round(axis_energy_reco.bounds[0].value,3),\n",
    "                                                              np.round(axis_energy_reco.bounds[1].value,3)\n",
    "                                                             )\n",
    "    range_message+= str(axis_energy_reco.unit)+f\". Energy bins: {axis_energy_reco.nbin}.\\n\"\n",
    "    print(range_message)\n",
    "\n",
    "    dummy_array = axis_energy_reco.edges - custom_range_energy_reco[0]\n",
    "    i_start_energy_reco = np.argmin(np.abs(dummy_array.value))\n",
    "    \n",
    "    dummy_array = axis_energy_reco.edges - custom_range_energy_reco[1]\n",
    "    i_stop_energy_reco  = np.argmin(np.abs(dummy_array.value))\n",
    "    \n",
    "    axis_energy_reco = axis_energy_reco.slice(slice(i_start_energy_reco, i_stop_energy_reco))\n",
    "    \n",
    "    range_message = 'Current  energy range: [{}, {}] '.format(np.round(axis_energy_reco.bounds[0].value,3),\n",
    "                                                              np.round(axis_energy_reco.bounds[1].value,3)\n",
    "                                                             )\n",
    "    range_message+= str(axis_energy_reco.unit)+f\". Energy bins: {axis_energy_reco.nbin}.\\n\"\n",
    "    print(range_message)\n",
    "    \n",
    "    \n",
    "# Print\n",
    "print(axis_energy_reco)\n",
    "# reco_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab2e58",
   "metadata": {},
   "source": [
    "Define the True Energy Axis.\n",
    "\n",
    "This is done from the SPECRESP MATRIX hdu of the response file.\n",
    "This name might change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e4c78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "specresp_matrix = hdulist_rsp['SPECRESP MATRIX'].header['EXTNAME']\n",
    "\n",
    "# Define the True Energy Axis\n",
    "true_table = Table.read( hdulist_rsp[specresp_matrix] )\n",
    "\n",
    "true_energy_min = true_table[\"ENERG_LO\"].quantity\n",
    "true_energy_max = true_table[\"ENERG_HI\"].quantity\n",
    "\n",
    "# To avoid that min edge is 0\n",
    "true_energy_min[0] += 1e-2 * (true_energy_max[0] - true_energy_min[0])\n",
    "\n",
    "# Define Edges\n",
    "true_energy_edges = np.append(true_energy_min.value, true_energy_max.value[-1]) * true_energy_min.unit\n",
    "\n",
    "# Define Axis\n",
    "axis_energy_true = MapAxis.from_edges(true_energy_edges,\n",
    "                                      name = \"energy_true\",\n",
    "                                      interp = INTERP\n",
    "                                     )\n",
    "\n",
    "# Slice by finding the clostes edges in the energy axis to the requested bounds.\n",
    "if slice_energy:\n",
    "    \n",
    "    range_message = 'Original energy range: [{}, {}] '.format(np.round(axis_energy_true.bounds[0].value,3),\n",
    "                                                              np.round(axis_energy_true.bounds[1].value,3)\n",
    "                                                             )\n",
    "    range_message+= str(axis_energy_true.unit)+f\". Energy bins: {axis_energy_true.nbin}.\\n\"\n",
    "    print(range_message)\n",
    "    \n",
    "    dummy_array = axis_energy_true.edges - custom_range_energy_true[0]\n",
    "    i_start_energy_true = np.argmin(np.abs(dummy_array.value))\n",
    "    \n",
    "    dummy_array = axis_energy_true.edges - custom_range_energy_true[1]\n",
    "    i_stop_energy_true  = np.argmin(np.abs(dummy_array.value))\n",
    "    \n",
    "    axis_energy_true = axis_energy_true.slice(slice(i_start_energy_true, i_stop_energy_true))\n",
    "    \n",
    "    range_message = 'Current  energy range: [{}, {}] '.format(np.round(axis_energy_true.bounds[0].value,3),\n",
    "                                                              np.round(axis_energy_true.bounds[1].value,3)\n",
    "                                                             )\n",
    "    range_message+= str(axis_energy_true.unit)+f\". Energy bins: {axis_energy_true.nbin}.\\n\"\n",
    "    print(range_message)\n",
    "\n",
    "\n",
    "# Print\n",
    "print(axis_energy_true)\n",
    "# true_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed18706",
   "metadata": {},
   "source": [
    "#### 1.5 - Load the Spectral Response Matrix: Effective Area vs True and Reconstructed Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bc084",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_hdu = hdulist_rsp[specresp_matrix]\n",
    "Matrix_header = Matrix_hdu.header\n",
    "Matrix_data = Matrix_hdu.data\n",
    "\n",
    "Matrix_array = np.zeros([len(Matrix_data), Matrix_header[\"DETCHANS\"]], dtype = np.float64)\n",
    "\n",
    "for i, l in enumerate(Matrix_data):\n",
    "    if l.field(\"N_GRP\"):\n",
    "        m_start = 0\n",
    "        for k in range(l.field(\"N_GRP\")):\n",
    "            \n",
    "            if np.isscalar(l.field(\"N_CHAN\")):\n",
    "                f_chan = l.field(\"F_CHAN\") - 1\n",
    "                n_chan = l.field(\"N_CHAN\")\n",
    "            else:\n",
    "                f_chan = l.field(\"F_CHAN\")[k] - 1\n",
    "                n_chan = l.field(\"N_CHAN\")[k]\n",
    "\n",
    "            Matrix_array[i, f_chan : f_chan+n_chan] = l.field(\"MATRIX\")[m_start : m_start+n_chan]\n",
    "            m_start += n_chan\n",
    "\n",
    "# Values are set, now define the unit of measure.\n",
    "Matrix_unit = true_table['MATRIX'].unit\n",
    "\n",
    "if slice_energy:\n",
    "    Matrix_array = Matrix_array[i_start_energy_true:i_stop_energy_true, i_start_energy_reco:i_stop_energy_reco]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf028d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total Effective Area\n",
    "# Total_aeff = np.sum(Matrix_array) * Matrix_unit\n",
    "# print(f'Total effective area: {Total_aeff}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebc587",
   "metadata": {},
   "source": [
    "#### 1.6 - Define the Effective Area\n",
    "\n",
    "Plot the Effective Area vs True Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Effective Area array (as a function of True Energy)\n",
    "aeff_array = np.sum(Matrix_array, axis=1)\n",
    "\n",
    "# Compute Effective Area matrix (as a function of True Energy and Offset)\n",
    "aeff_matrix = np.ndarray( (axis_energy_true.nbin, axis_offset.nbin) )\n",
    "for i in range(axis_offset.nbin):\n",
    "    aeff_matrix.transpose()[i] = aeff_array\n",
    "\n",
    "# Instantiate Effective Area object\n",
    "aeff = EffectiveAreaTable2D(axes = [axis_energy_true, axis_offset],\n",
    "                            data = aeff_matrix,\n",
    "                            unit = Matrix_unit\n",
    "                            # meta = metadata dictionary from header\n",
    "                           )\n",
    "\n",
    "# Print\n",
    "print(aeff)\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,4))\n",
    "\n",
    "aeff.plot_energy_dependence(ax = axs[0], offset = None)\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "\n",
    "aeff.plot(ax = axs[1], add_cbar = True)\n",
    "axs[1].set_xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02285f92",
   "metadata": {},
   "source": [
    "## 2 - Source geometry and Energy Dispersion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbceb6a",
   "metadata": {},
   "source": [
    "#### 2.1 - Define Source Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d82b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define the Source Geometry: a region in the sky where the source is placed.\n",
    "# This represents a single pixel on the sky.\n",
    "\n",
    "geometry_radius = 5.0 * u.deg\n",
    "source_geometry_str = FRAME+';circle('+str(RA_OBJ)+', '+str(DEC_OBJ)+', '+str(geometry_radius.value)+')'\n",
    "\n",
    "# Geometry object: a sky region covered by a pixel, with arbitrary shape and size\n",
    "geom = RegionGeom.create(source_geometry_str, axes = [axis_energy_reco])\n",
    "\n",
    "# Print\n",
    "print(geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd481c19",
   "metadata": {},
   "source": [
    "#### 2.2 - Define Energy Dispersion Matrix\n",
    "\n",
    "P.S. We need to add an exposure map (effective area * observation livetime vs true energy) after we define the livetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a95a47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build Kernel\n",
    "edisp = EDispKernel(axes = [axis_energy_true, axis_energy_reco], data = Matrix_array)\n",
    "\n",
    "# Build EDispKernelMap\n",
    "edisp = EDispKernelMap.from_edisp_kernel(edisp, geom = geom)\n",
    "\n",
    "# Normalize data\n",
    "Matrix_normalized = np.zeros(np.shape(edisp.edisp_map.data.T[0][0].T))\n",
    "for i, r in enumerate(edisp.edisp_map.data.T[0][0].T):\n",
    "    norm_row = np.sum(r)\n",
    "    if norm_row != 0.0:\n",
    "        Matrix_normalized[i] = r / norm_row\n",
    "    \n",
    "Matrix_normalized = np.reshape(Matrix_normalized, np.shape(edisp.edisp_map.data))\n",
    "edisp.edisp_map.data = Matrix_normalized\n",
    "\n",
    "# Peek\n",
    "edisp.peek()\n",
    "\n",
    "# Check Normalization\n",
    "# for r in edisp.edisp_map.data.T[0][0].T:\n",
    "#     print(len(r), np.sum(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0977b59",
   "metadata": {},
   "source": [
    "#### Define Energy Dispersion from a gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ddea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build Gaussian Kernel\n",
    "# edisp_gauss = EDispKernel.from_gauss(energy_axis_true = axis_energy_true,\n",
    "#                                      energy_axis      = axis_energy_reco,\n",
    "#                                      bias             = 0,\n",
    "#                                      sigma            = 0.1\n",
    "#                                     )\n",
    "# # Build Gaussian EDispKernelMap\n",
    "# edisp_gauss = EDispKernelMap.from_edisp_kernel(edisp_gauss, geom = geom)\n",
    "\n",
    "# # Peek\n",
    "# edisp_gauss.peek()\n",
    "\n",
    "# # Check normalization\n",
    "# for r in edisp_gauss.edisp_map.data.T[0][0].T:\n",
    "#     print(len(r), np.sum(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddd5c7",
   "metadata": {},
   "source": [
    "## 3 - Load the Background\n",
    "\n",
    "This is used to define the Backrgound Spectral Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d83041",
   "metadata": {},
   "source": [
    "Load the Background File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist_bak = fits.open(file_bak)\n",
    "\n",
    "# Print the Information and Primary Header\n",
    "print(hdulist_bak.info())\n",
    "# hdulist_bak['PRIMARY'].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Background Table\n",
    "bak_table_ebounds = Table.read( hdulist_bak['EBOUNDS' ] )\n",
    "bak_table_spectrum= Table.read( hdulist_bak['SPECTRUM'] )\n",
    "\n",
    "bak_table = Table()\n",
    "bak_table['CHANNEL'] = bak_table_ebounds['CHANNEL']\n",
    "bak_table['E_MIN'  ] = bak_table_ebounds['E_MIN'  ] * u.keV\n",
    "bak_table['E_MAX'  ] = bak_table_ebounds['E_MAX'  ] * u.keV\n",
    "bak_table['RATE'   ] = bak_table_spectrum['RATE'  ] * u.s**(-1)\n",
    "\n",
    "bak_table['BKG_MOD'] = bak_table['RATE'].quantity / (bak_table['E_MAX'].quantity-bak_table['E_MIN'].quantity)\n",
    "\n",
    "###############################################################\n",
    "bak_table['BKG_MOD'] = bak_table['BKG_MOD']/ geom.solid_angle()\n",
    "###############################################################\n",
    "\n",
    "# Print\n",
    "# bak_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Background Reconstructed Energy Axis and slice it.\n",
    "# It may be slightly different from the DRM Reco energy axis.\n",
    "\n",
    "bak_energy_min = bak_table['E_MIN'].quantity\n",
    "bak_energy_max = bak_table['E_MAX'].quantity\n",
    "\n",
    "reco_energy_edges_bkg = np.append(bak_energy_min.value, bak_energy_max.value[-1]) * bak_energy_min.unit\n",
    "axis_energy_reco_bkg  = MapAxis.from_edges(reco_energy_edges_bkg,\n",
    "                                           name = \"energy\",\n",
    "                                           interp = INTERP\n",
    "                                          )\n",
    "if slice_energy:\n",
    "    \n",
    "    range_message = 'Original energy range: [{}, {}] '.format(np.round(axis_energy_reco_bkg.bounds[0].value,3),\n",
    "                                                              np.round(axis_energy_reco_bkg.bounds[1].value,3)\n",
    "                                                             )\n",
    "    range_message+= str(axis_energy_reco_bkg.unit)+\".\\n\"\n",
    "    print(range_message)\n",
    "\n",
    "    dummy_array = axis_energy_reco_bkg.edges - custom_range_energy_reco[0]\n",
    "    i_start_energy_reco_bkg = np.argmin(np.abs(dummy_array.value))\n",
    "    \n",
    "    dummy_array = axis_energy_reco_bkg.edges - custom_range_energy_reco[1]\n",
    "    i_stop_energy_reco_bkg  = np.argmin(np.abs(dummy_array.value))\n",
    "    \n",
    "    axis_energy_reco_bkg = axis_energy_reco_bkg.slice(slice(i_start_energy_reco_bkg, i_stop_energy_reco_bkg))\n",
    "    \n",
    "    range_message = 'Current  energy range: [{}, {}] '.format(np.round(axis_energy_reco_bkg.bounds[0].value,3),\n",
    "                                                              np.round(axis_energy_reco_bkg.bounds[1].value,3)\n",
    "                                                             )\n",
    "    range_message+= str(axis_energy_reco_bkg.unit)+\".\\n\"\n",
    "    print(range_message)\n",
    "    \n",
    "    bak_table = bak_table[i_start_energy_reco_bkg: i_stop_energy_reco_bkg]\n",
    "    \n",
    "# Print\n",
    "print(axis_energy_reco_bkg)\n",
    "# bak_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a81380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Background Matrix (as a function of energy, lon and lat) as ndarray\n",
    "data_bkg = np.ndarray( (axis_energy_reco_bkg.nbin, axis_fovlon.nbin, axis_fovlat.nbin) )\n",
    "\n",
    "for i in range(axis_fovlat.nbin):\n",
    "    for j in range(axis_fovlon.nbin):\n",
    "        data_bkg.transpose()[i][j] = bak_table['BKG_MOD'].value\n",
    "\n",
    "# Instantiate Background object # I should add meta=metadata dictionary from header    \n",
    "bkg = Background3D(axes = [axis_energy_reco_bkg, axis_fovlon, axis_fovlat],\n",
    "                   data = data_bkg,\n",
    "                   unit = bak_table['BKG_MOD'].unit,\n",
    "                   #is_pointlike = False,\n",
    "                   #fov_alignment = FoVAlignment.RADEC,\n",
    "                   #meta = None,\n",
    "                   #interp_kwargs = None\n",
    "                   )\n",
    "\n",
    "# Print\n",
    "print(bkg)\n",
    "\n",
    "# Plot\n",
    "bkg.peek()\n",
    "plt.show()\n",
    "\n",
    "# Plot as I want\n",
    "f, a = plt.subplots(1, figsize=(6,5))\n",
    "a.step(axis_energy_reco_bkg.center.value,\n",
    "       bkg.data.T[0][0],\n",
    "       color = 'C3'\n",
    "      )\n",
    "a.set_xscale('log')\n",
    "a.set_yscale('log')\n",
    "a.set_xlabel('Energy [keV]', fontsize = 'large')\n",
    "a.set_ylabel('Background rate [1 / (s keV sr)]', fontsize = 'large')\n",
    "a.set_title('Background Spectral Model', fontsize = 'large')\n",
    "a.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9050b",
   "metadata": {},
   "source": [
    "#### Now create the IRFs dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "IRFs = {'aeff' : aeff,\n",
    "        'bkg'  : bkg\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690f18b",
   "metadata": {},
   "source": [
    "## 4 - Define Temporal and Spectral Model for the simulated source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal model\n",
    "\n",
    "GBM_original = QTable.read(GBM_original_name, format = 'fits')\n",
    "\n",
    "Temporal_Model_Table_Metadata = {'MJDREFI' : int(np.modf(trigger_time_t0.mjd)[1]),\n",
    "                                 'MJDREFF' :     np.modf(trigger_time_t0.mjd)[0],\n",
    "                                 'TIMEUNIT': GBM_original['time'].unit.to_string(),\n",
    "                                 'TIMESYS' : trigger_time_t0.scale\n",
    "                                }\n",
    "\n",
    "Temporal_Model_Table = Table(meta = Temporal_Model_Table_Metadata)\n",
    "Temporal_Model_Table['TIME'] = GBM_original['time']\n",
    "Temporal_Model_Table['NORM'] = GBM_original['norm']\n",
    "\n",
    "temporal_model = LightCurveTemplateTemporalModel(Temporal_Model_Table)\n",
    "\n",
    "# Print\n",
    "print(temporal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2102e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Temporal model at maximum, should return 1\n",
    "# print(temporal_model.evaluate(trigger_time_t0.mjd+0.075/86400.0))\n",
    "\n",
    "# Evaluate correction factor\n",
    "spectral_fit_time_range = [trigger_time_t0.mjd + spectral_fit_time_range[0]/86400.0,\n",
    "                           trigger_time_t0.mjd + spectral_fit_time_range[1]/86400.0\n",
    "                          ]\n",
    "spectral_fit_time_range = Time(spectral_fit_time_range, format = 'mjd')\n",
    "\n",
    "correction_factor = temporal_model.integral(spectral_fit_time_range[0], spectral_fit_time_range[1])\n",
    "print(correction_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eece78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral model\n",
    "spectral_model = ExpCutoffPowerLawSpectralModel(amplitude = GBM_Ampli / correction_factor,\n",
    "                                                index     = - GBM_Index,\n",
    "                                                lambda_   = (2.0 + GBM_Index ) / GBM_Epeak,\n",
    "                                                reference = GBM_Erefe\n",
    "                                               )\n",
    "# Print\n",
    "print(spectral_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Source Model = Temporal & Spectral\n",
    "model_simu = SkyModel(spectral_model = spectral_model,\n",
    "                      temporal_model = temporal_model,\n",
    "                      name           = \"Compt-TwoPulse\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print\n",
    "fig, axs = plt.subplots(1,2, figsize = (15,5) )\n",
    "\n",
    "energy_bounds = [axis_energy_true.edges[0], axis_energy_true.edges[-1]]\n",
    "time_range    = [trigger_time_t0 - 0.3*u.s, trigger_time_t0 + 0.8*u.s ]\n",
    "\n",
    "spectral_model.plot(energy_bounds, ax = axs[0], sed_type = 'dnde')\n",
    "temporal_model.plot(time_range, ax = axs[1])\n",
    "\n",
    "axs[0].set_title('Spectral Model', fontsize = 'large')\n",
    "axs[1].set_title('Temporal Model', fontsize = 'large')\n",
    "axs[0].grid(which=\"both\")\n",
    "axs[1].grid(which=\"both\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_simu.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc58ebd",
   "metadata": {},
   "source": [
    "## 5 - Define observation number, time parameters and Energy Dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Number of observations\n",
    "n_obs = (t_stop_obs-t_start_obs)/live_t_obs\n",
    "n_obs = int(np.floor(n_obs.value))\n",
    "\n",
    "# Define starting time of each observation linearly spaced during the night\n",
    "starting_times = np.linspace(t_start_obs.value,\n",
    "                             t_stop_obs.value,\n",
    "                             num = n_obs\n",
    "                            )\n",
    "starting_times = starting_times.tolist() * time_unit\n",
    "\n",
    "# Define the duration of each observation as the difference between two following starting times\n",
    "# minus the rest time between them.\n",
    "livetimes = starting_times[1:] - starting_times[:-1] - dead_times\n",
    "\n",
    "# Remove last edge to have the same array dimesion for starting times and livetimes.\n",
    "starting_times = starting_times[:-1]\n",
    "\n",
    "# Turn them from astropy.units.quantity.Quantity to astropy.time.core.Time with t_ref\n",
    "starting_times = Time(trigger_time_t0 + starting_times)\n",
    "\n",
    "# Adjust n_obs\n",
    "n_obs = starting_times.size\n",
    "\n",
    "print(n_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac673fce",
   "metadata": {},
   "source": [
    "#### Slice original GBM Data in the time range of our simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4281876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the closed GBM time points \n",
    "GBM_i_start= np.argmin(np.abs(GBM_original['time'].value - t_start_obs.value))\n",
    "GBM_i_stop = np.argmin(np.abs(GBM_original['time'].value - t_stop_obs.value ))\n",
    "\n",
    "GBM_original_cut = GBM_original[GBM_i_start:GBM_i_stop]\n",
    "\n",
    "# GBM Data for plot\n",
    "\n",
    "# Time\n",
    "GBM_time_val = GBM_original_cut['time'  ].value\n",
    "GBM_time_wid = GBM_original_cut['time_width'].value\n",
    "\n",
    "# Count rates\n",
    "GBM_cnt_rate = GBM_original_cut['cnt_rt'    ].value\n",
    "GBM_cnt_erro = GBM_original_cut['cnt_rt_err'].value\n",
    "\n",
    "# Background rates\n",
    "GBM_bkg_rate = GBM_original_cut['bkg_rt'    ].value\n",
    "GBM_bkg_erro = GBM_original_cut['bkg_rt_err'].value\n",
    "\n",
    "# Excess rates\n",
    "GBM_exc_rate = GBM_cnt_rate - GBM_bkg_rate\n",
    "GBM_exc_erro = GBM_cnt_erro + GBM_bkg_erro\n",
    "\n",
    "# Model: best fit excess rates\n",
    "GBM_exc_pred = GBM_original_cut['best_model'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbec19d",
   "metadata": {},
   "source": [
    "#### Complete IRFs\n",
    "Now that the livetimes have been computed, complete the IRFs by adding an exposure map to the Edisp.\n",
    "It is not necessay for the code, since the SpectrumDatasets compute their own exposure, but I want to properly set the EDispKernelMap object by filling its own exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correct Units for exposure map\n",
    "edisp.exposure_map = edisp.exposure_map.to_unit(aeff.unit * time_unit)\n",
    "\n",
    "# Initialize the Exposure with effective area values * livetimes. Assume all lifetimes are equal\n",
    "edisp.exposure_map.data *= 0.0\n",
    "edisp.exposure_map.data += np.reshape( aeff.data.T[0], edisp.exposure_map.data.T.shape ).T\n",
    "edisp.exposure_map.data *= livetimes[0].value\n",
    "\n",
    "########################################## GAUSSIAN\n",
    "# # Set correct Units for exposure map\n",
    "# edisp_gauss.exposure_map = edisp_gauss.exposure_map.to_unit(aeff.unit * time_unit)\n",
    "\n",
    "# # Initialize the Exposure with effective area values * livetimes. Assume all lifetimes are equal\n",
    "# edisp_gauss.exposure_map.data += np.reshape(aeff.data.T[0], (1,1,1,80)).T\n",
    "# edisp_gauss.exposure_map.data *= livetimes[0].value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5eb572",
   "metadata": {},
   "source": [
    "# 6 - Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08bf1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a List of Datasets, each will be a Light curve\n",
    "List_of_Datasets = []\n",
    "# Fill it with empty Datasets\n",
    "for i_LC in range(Number_of_LightCurves):\n",
    "    List_of_Datasets.append(Datasets())\n",
    "    \n",
    "    \n",
    "# Create an empty SpectrumDataset object to host geometry and energy info.\n",
    "empty = SpectrumDataset.create(geom = geom,\n",
    "                               energy_axis_true = axis_energy_true,\n",
    "                               name = \"empty\",\n",
    "                               edisp = edisp\n",
    "                              )\n",
    "\n",
    "# Create Maker object.\n",
    "# containment_correction must be set True if I have a PSF, to adapt the\n",
    "# exposure map and account for PSF broadening and the PSF containment.\n",
    "maker = SpectrumDatasetMaker(selection = [\"exposure\",\n",
    "                                          \"background\"\n",
    "                                         ],\n",
    "                             containment_correction = False\n",
    "                            )\n",
    "\n",
    "# This mock light curve will store info on the predicted background and excess rates.\n",
    "# It won't contain any simulation.\n",
    "datasets_generic = Datasets()\n",
    "\n",
    "for idx in range(n_obs):\n",
    "    print(f'Creating Dataset {idx+1}/{n_obs}...             \\r', end = '')\n",
    "    \n",
    "    # Set the current observation. Observations differ only in their starting time.\n",
    "    obs = Observation.create(pointing      = pointing,\n",
    "                             livetime      = livetimes[idx],\n",
    "                             tstart        = starting_times[idx],\n",
    "                             irfs          = IRFs,\n",
    "                             reference_time= trigger_time_t0,\n",
    "                             obs_id        = idx\n",
    "                            )\n",
    "    \n",
    "    # Set name according to observation number. Set geometry and energy information.\n",
    "    dataset_generic = empty.copy(name = f\"dataset-{idx}\")\n",
    "    \n",
    "    # Run: creates the SpectrumDataset. It also sets the Background counts.\n",
    "    dataset_generic = maker.run(dataset_generic, obs)\n",
    "    \n",
    "    # Set the Energy Disperison    \n",
    "    dataset_generic.edisp = edisp\n",
    "    \n",
    "    # Set the source model and compute the predicted excess counts from it.\n",
    "    dataset_generic.models = model_simu\n",
    "    \n",
    "    # For this observation simulate background and counts for each different light curve\n",
    "    for i_LC in range(Number_of_LightCurves):\n",
    "               \n",
    "        dataset = dataset_generic.copy(name = f\"LC-{i_LC}\"+f\"--Dataset-{idx}\")\n",
    "        \n",
    "        # Set models, that CANNOT BE COPIED\n",
    "        dataset.models = model_simu\n",
    "        \n",
    "        # Introduce Background Fluctuations.\n",
    "        random_state = get_random_state('random-seed')\n",
    "        data = np.nan_to_num(dataset.npred_background().data,\n",
    "                             copy = True, nan = 0.0, posinf = 0.0, neginf = 0.0)\n",
    "        data = random_state.poisson(data)\n",
    "        dataset.npred_background().data = data\n",
    "        dataset.background = dataset.npred_background()\n",
    "        \n",
    "        # Simulate counts from Poisson(avg=Predicted Backgrounds+Predicted count excess)\n",
    "        dataset.fake()\n",
    "        \n",
    "        # Add this dataset to the right collection.\n",
    "        datasets = List_of_Datasets[i_LC]\n",
    "        datasets.append(dataset)\n",
    "    \n",
    "    \n",
    "    datasets_generic.append(dataset_generic)\n",
    "    \n",
    "        \n",
    "    # Repeat for a new observation.\n",
    "    \n",
    "# Loop ended.\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86603001",
   "metadata": {},
   "source": [
    "# 7 - Plot and explore results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa98cf",
   "metadata": {},
   "source": [
    "The model and background information can be seen in the *generic* datasets, where counts have not been faked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quicklook_table_generic = datasets_generic.info_table()\n",
    "\n",
    "print('Columns available:\\n', quicklook_table_generic.keys())\n",
    "\n",
    "show_columns = ['name',\n",
    "                'background',\n",
    "                'npred_signal',\n",
    "                'npred',\n",
    "                'counts',              \n",
    "                'livetime',\n",
    "                'counts_rate',\n",
    "                'background_rate',\n",
    "                'excess_rate'\n",
    "               ]\n",
    "quicklook_table_generic[show_columns][54:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d92cc",
   "metadata": {},
   "source": [
    "Quick look to a Light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "quicklook_table = List_of_Datasets[0].info_table()\n",
    "\n",
    "print('Columns available:\\n',quicklook_table.keys())\n",
    "\n",
    "show_columns = ['name',\n",
    "                'background',\n",
    "                'npred_signal',\n",
    "                'npred',\n",
    "                'counts',              \n",
    "                'livetime',\n",
    "                'counts_rate',\n",
    "                'background_rate',\n",
    "                'excess_rate'\n",
    "               ]\n",
    "quicklook_table[show_columns][54:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12456e0c",
   "metadata": {},
   "source": [
    "Average quantities of the Light Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ddd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = Number_of_LightCurves\n",
    "n_cols = n_obs\n",
    "    \n",
    "SIM_matrix_cnt_rate = np.empty( (n_rows, n_cols) )\n",
    "SIM_matrix_bkg_rate = np.empty( (n_rows, n_cols) )\n",
    "\n",
    "print('Extracting rates from table...')\n",
    "for i in range(n_rows):\n",
    "    table_i = List_of_Datasets[i].info_table()\n",
    "    SIM_matrix_cnt_rate[i] = table_i['counts_rate'    ].value\n",
    "    SIM_matrix_bkg_rate[i] = table_i['background_rate'].value\n",
    "\n",
    "print('Computing averages...')\n",
    "# Count rates\n",
    "AVG_cnt_rate = np.mean(SIM_matrix_cnt_rate, axis = 0)\n",
    "AVG_cnt_erro = np.std( SIM_matrix_cnt_rate, axis = 0, ddof = 1)\n",
    "        \n",
    "# Background rates    \n",
    "AVG_bkg_rate = np.mean(SIM_matrix_bkg_rate, axis = 0)\n",
    "AVG_bkg_erro = np.std( SIM_matrix_bkg_rate, axis = 0, ddof = 1)\n",
    "        \n",
    "# Excess Rates\n",
    "AVG_exc_rate = AVG_cnt_rate - AVG_bkg_rate\n",
    "AVG_exc_erro = np.std( SIM_matrix_cnt_rate - SIM_matrix_bkg_rate, axis = 0, ddof = 1)\n",
    "        \n",
    "# Predicted Signal Rates and Predicted background\n",
    "AVG_exc_pred = datasets_generic.info_table()['npred_signal'].value / livetimes.value\n",
    "AVG_bkg_pred = datasets_generic.info_table()['background_rate'].value\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_light_curve(avg, figsize = (15.0, 22.0),curve_index = 0, save_figures_directory = None):\n",
    "    \n",
    "    # Time\n",
    "    SIM_time_val = starting_times + livetimes / 2.0 - trigger_time_t0\n",
    "    SIM_time_val = SIM_time_val.sec\n",
    "    SIM_time_wid = livetimes.value\n",
    "    \n",
    "    if avg:\n",
    "        # Count rates\n",
    "        SIM_cnt_rate = AVG_cnt_rate\n",
    "        SIM_cnt_erro = AVG_cnt_erro\n",
    "        \n",
    "        # Background rates    \n",
    "        SIM_bkg_rate = AVG_bkg_rate\n",
    "        SIM_bkg_erro = AVG_bkg_erro\n",
    "        \n",
    "        # Excess Rates\n",
    "        SIM_exc_rate = AVG_exc_rate\n",
    "        SIM_exc_erro = AVG_exc_erro\n",
    "        \n",
    "        # Predicted Signal Rates\n",
    "        SIM_exc_pred = AVG_exc_pred\n",
    "    \n",
    "    else:\n",
    "        # Choose one Light Curve\n",
    "        datasets = List_of_Datasets[curve_index].info_table()\n",
    "        \n",
    "        # Count rates\n",
    "        SIM_cnt_rate = datasets['counts_rate'].value\n",
    "        SIM_cnt_erro = SIM_cnt_rate / np.sqrt(datasets['counts'].value)\n",
    "        \n",
    "        # Background rates    \n",
    "        SIM_bkg_rate = datasets['background_rate'].value\n",
    "        SIM_bkg_erro = SIM_bkg_rate / np.sqrt(datasets['background'].value)\n",
    "        \n",
    "        # Excess Rates\n",
    "        SIM_exc_rate = datasets['excess_rate'].value\n",
    "        SIM_exc_erro = SIM_cnt_erro + SIM_bkg_erro\n",
    "        \n",
    "        # Predicted Signal Rates\n",
    "        SIM_exc_pred = datasets['npred_signal'].value / SIM_time_wid     \n",
    "    \n",
    "    ###################################################################\n",
    "    # Define pyplot Figure and Axes\n",
    "    fig, axs = plt.subplots(3,\n",
    "                            figsize = figsize,\n",
    "                            gridspec_kw = {'height_ratios': [2.5, 2.5, 1]}\n",
    "                           )\n",
    "    \n",
    "    # DATA PLOT\n",
    "    \n",
    "    # Plot GBM Data + Error\n",
    "    axs[0].step(GBM_time_val,\n",
    "                GBM_cnt_rate,\n",
    "                label = 'GBM Count rates', color = 'C1', where = 'mid'\n",
    "               )\n",
    "    axs[0].bar(x      = GBM_time_val,\n",
    "               height = GBM_cnt_erro * 2.0,\n",
    "               bottom = GBM_cnt_rate - GBM_cnt_erro,\n",
    "               width  = GBM_time_wid,\n",
    "               align  = 'center', color = 'C1', alpha = 0.5\n",
    "              )\n",
    "        \n",
    "    # Plot GBM Background + Error\n",
    "    axs[0].step(GBM_time_val,\n",
    "                GBM_bkg_rate,\n",
    "                label = 'GBM bkgd rates', color = 'C3', where = 'mid'\n",
    "               )\n",
    "    axs[0].bar(x      = GBM_time_val,\n",
    "               height = GBM_bkg_erro * 2.0,\n",
    "               bottom = GBM_bkg_rate - GBM_bkg_erro,\n",
    "               width  = GBM_time_wid,\n",
    "               align  = 'center', color = 'C3', alpha = 0.5\n",
    "              )\n",
    "        \n",
    "    # Plot Simulated Light Curve + Error\n",
    "    axs[0].step(SIM_time_val,\n",
    "                SIM_cnt_rate,\n",
    "                label = 'Simulated Count rates', color = 'C0', where = 'mid'\n",
    "               )\n",
    "    axs[0].bar(x      = SIM_time_val,\n",
    "               height = SIM_cnt_erro * 2.0,\n",
    "               bottom = SIM_cnt_rate - SIM_cnt_erro,\n",
    "               width  = SIM_time_wid,\n",
    "               align  = 'center', color = 'C0', alpha = 0.5\n",
    "              )\n",
    "        \n",
    "    # Plot Simulated Background + Error\n",
    "    axs[0].step(SIM_time_val,\n",
    "                SIM_bkg_rate,\n",
    "                label = 'Simulated Bkgd rates', color = 'b', where = 'mid'\n",
    "               )\n",
    "    axs[0].bar(x      = SIM_time_val,\n",
    "               height = SIM_bkg_erro * 2.0,\n",
    "               bottom = SIM_bkg_rate - SIM_bkg_erro,\n",
    "               width  = SIM_time_wid,\n",
    "               align  = 'center', color = 'b', alpha = 0.5\n",
    "              )\n",
    "    \n",
    "    # EXCESS PLOT\n",
    "    \n",
    "    # Plot GBM Excess rates   \n",
    "    axs[1].step(GBM_time_val,\n",
    "                GBM_exc_rate,\n",
    "                label = 'GBM Excess rates', color = 'C1', where = 'mid'\n",
    "               )\n",
    "    axs[1].bar(x = GBM_time_val,\n",
    "               height = GBM_exc_erro * 2.0,\n",
    "               bottom = GBM_exc_rate - GBM_exc_erro,\n",
    "               width  = GBM_time_wid,\n",
    "               align  = 'center', color = 'C1', alpha = 0.5\n",
    "              )\n",
    "        \n",
    "    # Plot GBM excess prediction: Best fit model\n",
    "    axs[1].plot(GBM_time_val,\n",
    "                GBM_exc_pred,\n",
    "                label = 'GBM Best Fit Model', color = 'C3'\n",
    "               )\n",
    "        \n",
    "    # Plot Simulated Exccess rates\n",
    "    axs[1].step(SIM_time_val,\n",
    "                SIM_exc_rate,\n",
    "                label = 'Simulated Excess rates', color = 'C0', where = 'mid'\n",
    "               )\n",
    "    axs[1].bar(x = SIM_time_val,\n",
    "               height = SIM_exc_erro * 2.0,\n",
    "               bottom = SIM_exc_rate - SIM_exc_erro,\n",
    "               width  = SIM_time_wid,\n",
    "               align  = 'center', color = 'C0', alpha = 0.5\n",
    "              )\n",
    "                \n",
    "    # Plot Predicted Rate (Gammapy model through IRFs)\n",
    "    axs[1].plot(SIM_time_val,\n",
    "                SIM_exc_pred,\n",
    "                label = 'Gammapy Model Predicted Excess', color = 'b'\n",
    "               )\n",
    "        \n",
    "    # BACKGROUND ZOOM    \n",
    "    \n",
    "    # Plot GBM Background + Error\n",
    "    axs[2].step(GBM_time_val,\n",
    "                GBM_bkg_rate,\n",
    "                label = 'GBM bkgd rates', color = 'C3', where = 'mid'\n",
    "               )\n",
    "    axs[2].bar(x      = GBM_time_val,\n",
    "               height = GBM_bkg_erro * 2.0,\n",
    "               bottom = GBM_bkg_rate - GBM_bkg_erro,\n",
    "               width  = GBM_time_wid,\n",
    "               align  = 'center', color = 'C3', alpha = 0.5\n",
    "              )\n",
    "        \n",
    "    # Plot Simulated Background + Error\n",
    "    axs[2].step(SIM_time_val,\n",
    "                SIM_bkg_rate,\n",
    "                label = 'Simulated Bkgd rates', color = 'b', where = 'mid'\n",
    "               )\n",
    "    axs[2].bar(x      = SIM_time_val,\n",
    "               height = SIM_bkg_erro * 2.0,\n",
    "               bottom = SIM_bkg_rate - SIM_bkg_erro,\n",
    "               width  = SIM_time_wid,\n",
    "               align  = 'center', color = 'b', alpha = 0.5\n",
    "              )\n",
    "    \n",
    "    # Plot Mean of the simulated Background    \n",
    "    axs[2].hlines(y = AVG_bkg_pred,\n",
    "                  xmin = SIM_time_val[0],\n",
    "                  xmax = SIM_time_val[-1],\n",
    "                  linewidth = 2, color = 'C2', label = 'Gammapy predicted background'\n",
    "                 )    \n",
    "    \n",
    "    # LABELS\n",
    "    axs[0].set_xlabel('Time since trigger (s)', fontsize = 'large')\n",
    "    axs[1].set_xlabel('Time since trigger (s)', fontsize = 'large')\n",
    "    axs[2].set_xlabel('Time since trigger (s)', fontsize = 'large')\n",
    "    axs[0].set_ylabel('Count rates (cts/s)', fontsize = 'large')\n",
    "    axs[1].set_ylabel('Count rates (cts/s)', fontsize = 'large')\n",
    "    axs[2].set_ylabel('Count rates (cts/s)', fontsize = 'large')\n",
    "    \n",
    "    axs[0].set_xlim(SIM_time_val[0], SIM_time_val[-1])\n",
    "    axs[1].set_xlim(SIM_time_val[0], SIM_time_val[-1])\n",
    "    axs[2].set_xlim(SIM_time_val[0], SIM_time_val[-1])\n",
    "    \n",
    "    # TITLE PLOT\n",
    "    if avg:\n",
    "        plot_title = f'Average of {Number_of_LightCurves} simulated light curves. '\n",
    "        \n",
    "    else:\n",
    "        plot_title = f'Lightcurve simulation {curve_index+1}/{Number_of_LightCurves}. '\n",
    "        \n",
    "    plot_title += \"Data of \"+ title_name_transient\n",
    "    plot_title += \" from \"  + title_name_instrument +'.'\n",
    "    \n",
    "    axs[0].set_title(plot_title, fontsize = 'large')\n",
    "    axs[1].set_title(plot_title, fontsize = 'large')\n",
    "    axs[2].set_title(plot_title, fontsize = 'large')\n",
    "    \n",
    "    # OTHER    \n",
    "    axs[0].grid()\n",
    "    axs[1].grid()\n",
    "    axs[2].grid()\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    axs[2].legend()\n",
    "    \n",
    "    if save_figures_directory is not None:\n",
    "        if avg:\n",
    "            save_figures_filename = save_figures_directory + title_name_prefix + \"lightcurves_average\"\n",
    "        else:\n",
    "            save_figures_filename = save_figures_directory + title_name_prefix + \"lightcurve_\"+f\"{curve_index:02d}\"\n",
    "        \n",
    "        extents = [ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted()) for ax in axs]\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \".png\",\n",
    "                    facecolor = 'white'\n",
    "                   )\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \"_count_rates.png\",\n",
    "                    facecolor = 'white',\n",
    "                    bbox_inches = extents[0].expanded(1.2, 1.15)\n",
    "                   )\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \"_excess_rates.png\",\n",
    "                    facecolor = 'white',\n",
    "                    bbox_inches = extents[1].expanded(1.2, 1.15)\n",
    "                   )\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \"_backgrounds_rates.png\",\n",
    "                    facecolor = 'white',\n",
    "                    bbox_inches = extents[2].expanded(1.2, 1.35)\n",
    "                   )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b5c77",
   "metadata": {},
   "source": [
    "Plot the averaged light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b9592",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_light_curve(avg = True,\n",
    "                 figsize = (15.0, 24.0),\n",
    "                 save_figures_directory = output_directory\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182caab",
   "metadata": {},
   "source": [
    "Choose one light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e46e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_light_curve(avg = False,\n",
    "                 curve_index = 0,\n",
    "                 figsize = (15.0, 24.0),\n",
    "                 save_figures_directory = output_directory\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548b8bf",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_list = []\n",
    "hdu_list.append(fits.PrimaryHDU())\n",
    "\n",
    "qtable = QTable(datasets_generic.info_table())\n",
    "hdu_list.append(fits.table_to_hdu(qtable))\n",
    "\n",
    "for i_LC in range(Number_of_LightCurves):\n",
    "    qtable = QTable(List_of_Datasets[i_LC].info_table())\n",
    "    hdu_list.append(fits.table_to_hdu(qtable))\n",
    "    \n",
    "hdu_list = fits.HDUList(hdu_list)\n",
    "\n",
    "hdu_list.writeto(output_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255e4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2312fb01",
   "metadata": {},
   "source": [
    "# Flux Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = List_of_Datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the Temporal Model, attach only the Spectral Model to all SpectrumDataset objects\n",
    "# datasets.models = SkyModel(spectral_model = spectral_model, name = \"model-fit\")\n",
    "# datasets.models.to_parameters_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Estimate a Flux Points light curve, each point is the flux of an observation\n",
    "# # The estimator fits the norm of the source model component to datasets in each time interval GTI.\n",
    "# #%%time\n",
    "# lc_maker_1d = LightCurveEstimator(energy_edges = [axis_energy_true.edges[0], axis_energy_true.edges[-1]],#OR RECO?\n",
    "#                                   source = \"model-fit\",\n",
    "#                                   selection_optional = [\"ul\"]\n",
    "#                                  )\n",
    "# # \"all\": all the optional steps are executed\n",
    "# # \"errn-errp\": estimate asymmetric errors.\n",
    "# # \"ul\": estimate upper limits.\n",
    "# # \"scan\": estimate fit statistic profiles.\n",
    "\n",
    "# lc_1d = lc_maker_1d.run(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880adfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = lc_1d.plot(sed_type = \"flux\",  # \"dnde\", flux, eflux, e2dnde\n",
    "#                 energy_power = 1.0, # Power of energy to multiply flux axis with\n",
    "#                 marker = \"o\",\n",
    "#                 label = \"Simulated_LC\")\n",
    "\n",
    "# pl_start = ref_t0 - 0.3 * u.s\n",
    "# pl_end   = ref_t0 + 0.8 * u.s\n",
    "# #ax.set_xlim(pl_start.plot_date, pl_end.plot_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d7211",
   "metadata": {},
   "source": [
    "# Stacked Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = List_of_Datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c69cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the Datasets into one Spectrum Dataset\n",
    "# Stacked_spectrum_dataset = datasets.stack_reduce(name = 'Stacked_sim_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8646ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, figsize = (7,5))\n",
    "# Stacked_spectrum_dataset.plot_counts(ax=ax)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_title('Spectrum time-integrated (stacked)')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b270e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fb32c82",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gammapy.modeling.models import TemplateNPredModel\n",
    "\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].model\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].parameter_norm_only_changed\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].methods_sequence\n",
    "\n",
    "# if dataset_generic.evaluators['Compt-TwoPulse'].model.spatial_model:\n",
    "#     print('spatial model: true')\n",
    "# else: print('spatial model: false')\n",
    "    \n",
    "# print('psf_containment: ',dataset_generic.evaluators['Compt-TwoPulse'].psf_containment)\n",
    "\n",
    "# flux = dataset_generic.evaluators['Compt-TwoPulse'].compute_flux()\n",
    "\n",
    "# flux_expo = dataset_generic.evaluators['Compt-TwoPulse'].apply_exposure(flux)\n",
    "# flux_expo_edisp = dataset_generic.evaluators['Compt-TwoPulse'].apply_edisp(flux_expo)\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].edisp\n",
    "\n",
    "\n",
    "# #print(temporal_model)\n",
    "# #dataset_generic.npred_signal(model_name='Compt-TwoPulse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define PHA file\n",
    "# file_pha = input_directory + \"Output/grb_120323_A/grb_120323_A_n0.pha\"\n",
    "\n",
    "# # Define TTE fits file\n",
    "# file_tte = input_directory + \"FermiData/bn120323507/glg_tte_n0_bn120323507_v00.fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa42e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdulist_tte = fits.open(file_tte)\n",
    "# hdulist_tte.info()\n",
    "# hdulist_tte['PRIMARY'].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a file that contains information about the position\n",
    "#hdulist_pha = fits.open(file_pha)\n",
    "\n",
    "# Print the Information and Primary Header\n",
    "#print(hdulist_pha.info())\n",
    "# hdulist_pha['PRIMARY'].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6eea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Axis of Energy Migration\n",
    "# axis_energy_migr = MapAxis.from_bounds(0.1,\n",
    "#                                        2.0,\n",
    "#                                        nbin = 100,\n",
    "#                                        name = \"migra\")\n",
    "\n",
    "# # Instantiate Energy Dispersion Matrix object # I should add meta=metadata dictionary from header\n",
    "# edisp_gauss = EnergyDispersion2D.from_gauss(energy_axis_true = axis_energy_true,\n",
    "#                                             migra_axis       = axis_energy_migr,\n",
    "#                                             offset_axis      = axis_offset,\n",
    "#                                             bias             = 0,\n",
    "#                                             sigma            = 0.1,\n",
    "#                                             # interp           = 'lin' # Gaussian is in log\n",
    "#                                            )\n",
    "\n",
    "# # Print\n",
    "# print(edisp_gauss)\n",
    "# edisp_gauss.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ab472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The Spectral Response Matrix is in units of cm2. Divide by the total effective area\n",
    "# Matrix_edisp = Matrix_array / Total_aeff.value\n",
    "\n",
    "# # Transpose to better operate in loop\n",
    "# Matrix_edisp = Matrix_edisp.T\n",
    "\n",
    "# # The sum of each column (row after .T) must be 1\n",
    "# for m in Matrix_edisp:\n",
    "#     m = m / np.sum(m)\n",
    "    \n",
    "# # Transpose again\n",
    "# Matrix_edisp = Matrix_edisp.T\n",
    "\n",
    "\n",
    "\n",
    "# Plot Kernel\n",
    "# f,a = plt.subplots(figsize=(7,5))\n",
    "# edisp_kernel.plot_matrix(ax=a,add_cbar=True)\n",
    "# a.set_xscale('log')\n",
    "# a.set_yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# List_of_Datasets = []\n",
    "# for i_LC in range(Number_of_LightCurves):\n",
    "#     List_of_Datasets.append(Datasets())\n",
    "    \n",
    "    \n",
    "# # Create SpectrumDataset object.\n",
    "# empty = SpectrumDataset.create(geom = geom,\n",
    "#                                energy_axis_true = axis_energy_true,\n",
    "#                                name = \"empty\"\n",
    "#                               )\n",
    "# # Add exposure map\n",
    "# empty.edisp.exposure_map = IRFs['edisp'].exposure_map\n",
    "\n",
    "# # Create Maker object.\n",
    "# maker = SpectrumDatasetMaker(selection = [\"exposure\",\n",
    "#                                           \"background\",\n",
    "#                                           \"edisp\"\n",
    "#                                          ])\n",
    "# # This mock light curve will store info on the predicted background and excess rates.\n",
    "# # It won't contain any simulation.\n",
    "# datasets_generic = Datasets()\n",
    "\n",
    "# for idx in range(n_obs):\n",
    "    \n",
    "#     obs = Observation.create(pointing      = pointing,\n",
    "#                              livetime      = livetimes[idx],\n",
    "#                              tstart        = starting_times[idx],\n",
    "#                              irfs          = IRFs,\n",
    "#                              reference_time= trigger_time_t0,\n",
    "#                              obs_id        = idx\n",
    "#                             )\n",
    "    \n",
    "#     # Rename and pass geometry and energy information\n",
    "#     dataset_generic = empty.copy(name = f\"dataset-{idx}\")\n",
    "    \n",
    "#     # Compute Background\n",
    "#     dataset_generic = maker.run(dataset_generic, obs)\n",
    "    \n",
    "#     # Add exposure map (.run deletes it)\n",
    "#     dataset_generic.edisp.exposure_map = IRFs['edisp'].exposure_map\n",
    "    \n",
    "    \n",
    "#     # Add the source model and compute the predicted excess counts from it.\n",
    "#     dataset_generic.models = model_simu\n",
    "    \n",
    "#     # For this observation simulate background and counts for each different light curve\n",
    "#     for i_LC in range(Number_of_LightCurves):\n",
    "               \n",
    "#         dataset = dataset_generic.copy(name = f\"LC-{i_LC}\"+f\"--Dataset-{idx}\")\n",
    "        \n",
    "#         # Set models, that CANNOT BE COPIED\n",
    "#         dataset.models = model_simu\n",
    "        \n",
    "#         # Introduce Background Fluctuations.\n",
    "#         random_state = get_random_state('random-seed')\n",
    "#         data = np.nan_to_num(dataset.npred_background().data,\n",
    "#                              copy = True, nan = 0.0, posinf = 0.0, neginf = 0.0)\n",
    "#         data = random_state.poisson(data)\n",
    "#         dataset.npred_background().data = data\n",
    "#         dataset.background = dataset.npred_background()\n",
    "        \n",
    "#         # Simulate counts from Poisson(avg=Predicted Backgrounds+Predicted count excess)\n",
    "#         dataset.fake()\n",
    "        \n",
    "#         # Add this dataset to the right collection.\n",
    "#         datasets = List_of_Datasets[i_LC]\n",
    "#         datasets.append(dataset)\n",
    "    \n",
    "    \n",
    "#     datasets_generic.append(dataset_generic)\n",
    "    \n",
    "        \n",
    "#     # Repeat for a new observation.\n",
    "    \n",
    "# # Loop ended."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
