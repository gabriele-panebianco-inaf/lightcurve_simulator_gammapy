{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656375d9",
   "metadata": {},
   "source": [
    "# Create a Lightcurve Simulator in Gammapy-0.20\n",
    "\n",
    "This notebook is optimized to reproduce Fermi-GBM Light Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c697e4",
   "metadata": {},
   "source": [
    "## 0 - Setup: import packages of the environment gammapy-0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, cm\n",
    "from matplotlib.colors import LogNorm, PowerNorm\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table, QTable, hstack\n",
    "from astropy.io import fits\n",
    "\n",
    "import logging\n",
    "\n",
    "import os\n",
    "\n",
    "import yaml\n",
    "from yaml import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74044b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import Observation\n",
    "from gammapy.datasets import SpectrumDataset, Datasets, FluxPointsDataset\n",
    "from gammapy.estimators import LightCurveEstimator\n",
    "from gammapy.irf import (\n",
    "    EffectiveAreaTable2D,\n",
    "    Background2D, Background3D,\n",
    "    EnergyDispersion2D, EDispKernel, EDispKernelMap,\n",
    ")\n",
    "from gammapy.makers import SpectrumDatasetMaker\n",
    "from gammapy.maps import MapAxis, RegionGeom, TimeMapAxis\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    ExpCutoffPowerLawSpectralModel,\n",
    "    SkyModel,\n",
    "    LightCurveTemplateTemporalModel\n",
    ")\n",
    "from gammapy.utils.random import get_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4a208",
   "metadata": {},
   "source": [
    "## 0 - Setup: Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Define_Reference_Time(name_file_fits, name_hdu='PRIMARY'):\n",
    "    \"\"\"\n",
    "    Return the Burst Trigger Time as an `astropy.time.Time` object\n",
    "    to be used as Reference Time of the simulated observations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_file_fits: str\n",
    "        Name of a FITS file that must be opened to get the Trigger Time information.\n",
    "    name_hdu: str\n",
    "        Name of the HDU that contains the fields: 'TIMESYS', 'MJDREFI', 'MJDREFF', 'TRIGTIME'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `astropy.time.Time`\n",
    "    \"\"\"\n",
    "\n",
    "    hdulist = fits.open(name_file_fits)\n",
    "    Timesys = hdulist['PRIMARY'].header['TIMESYS'].lower()\n",
    "    Reference_time = hdulist['PRIMARY'].header['MJDREFI']\n",
    "    Reference_time+= hdulist['PRIMARY'].header['MJDREFF']\n",
    "    Reference_time+= hdulist['PRIMARY'].header['TRIGTIME'] / 86400.0\n",
    "    hdulist.close()\n",
    "\n",
    "    return Time(Reference_time, format = 'mjd', scale = Timesys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5448b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Define_Pointing_Direction(name_file_fits, name_hdu='PRIMARY'):\n",
    "    \"\"\"\n",
    "    Return the Pointing Direction as an `astropy.coordinates.SkyCoord` object\n",
    "    to be used as FoV (0,0) of the simulated observations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_file_fits: str\n",
    "        Name of a FITS file that must be opened to get the Pointing direction information.\n",
    "    name_hdu: str\n",
    "        Name of the HDU that contains the fields: 'RA_OBJ' and 'DEC_OBJ' in degrees, 'RADECSYS'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `astropy.coordinates.SkyCoord`\n",
    "    \"\"\"\n",
    "\n",
    "    hdulist = fits.open(name_file_fits)\n",
    "    RA_obj  = hdulist['PRIMARY'].header['RA_OBJ' ]\n",
    "    DEC_obj = hdulist['PRIMARY'].header['DEC_OBJ']\n",
    "    Frame   = hdulist['PRIMARY'].header['RADECSYS'].lower()\n",
    "    hdulist.close()\n",
    "\n",
    "    return SkyCoord(RA_obj, DEC_obj, unit = \"deg\", frame = Frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527be9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Define_Energy_Axis(name_file_fits,\n",
    "                       name_hdu,\n",
    "                       energy_is_true = False,\n",
    "                       interpolation_mode = \"log\",\n",
    "                       slice_energy = False,\n",
    "                       energy_custom_range = None\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    Returns an Energy Axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_file_fits: str\n",
    "        Name of a FITS file that must be opened to get the Energy Axis information.\n",
    "    name_hdu: str\n",
    "        Name of the HDU that contains the Energy Axis information.\n",
    "    energy_is_true: bool\n",
    "        True if we want to create a True Energy Axis, False for a Reconstructed Energy Axis.\n",
    "    interpolation_mode: str\n",
    "        Either \"lin\" or \"log\".\n",
    "    slice_energy: bool\n",
    "        True if you want to work with a custom energy range.\n",
    "    energy_custom_range: `astropy.units.Quantity`\n",
    "        A tuple with 2 values: start and stop of the requested energy range.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `gammapy.maps.MapAxis`\n",
    "    \"\"\"\n",
    "\n",
    "    # Load Energy Table\n",
    "    hdulist = fits.open(name_file_fits)\n",
    "    energy_table = Table.read(hdulist[name_hdu])\n",
    "    hdulist.close()\n",
    "\n",
    "    # True or Reconstructed Energy?        \n",
    "    if energy_is_true:\n",
    "        energy_col_names = (\"ENERG_LO\", \"ENERG_HI\")\n",
    "        energy_axis_name = \"energy_true\"\n",
    "    else:\n",
    "        energy_col_names = (\"E_MIN\", \"E_MAX\")\n",
    "        energy_axis_name = \"energy\"\n",
    "    \n",
    "    # Define Edges Columns\n",
    "    energy_col_min = energy_table[energy_col_names[0]].quantity\n",
    "    energy_col_max = energy_table[energy_col_names[1]].quantity\n",
    "    \n",
    "    if energy_col_min.unit is u.Unit(\"\"):\n",
    "        print(\"Adimensional values. Correct into \", energy_custom_range.unit)\n",
    "        energy_col_min = energy_col_min * energy_custom_range.unit\n",
    "        energy_col_max = energy_col_max * energy_custom_range.unit\n",
    "    \n",
    "    # To avoid that min edge is 0\n",
    "    energy_col_min[0] += 1e-2 * (energy_col_max[0] - energy_col_min[0])\n",
    "\n",
    "    # Define Edges\n",
    "    energy_edges = np.append(energy_col_min.value, energy_col_max.value[-1]) * energy_col_min.unit\n",
    "\n",
    "    # Define Axis\n",
    "    energy_axis = MapAxis.from_edges(energy_edges,\n",
    "                                      name = energy_axis_name,\n",
    "                                      interp = interpolation_mode\n",
    "                                     )\n",
    "    \n",
    "    # Slice Energy\n",
    "    if slice_energy:\n",
    "        range_message = f\"Original energy range: [{np.round(energy_axis.bounds[0].value,3)}, {np.round(energy_axis.bounds[1].value,3)}] \"\n",
    "        range_message+= str(energy_axis.unit) + f\". Energy bins: {energy_axis.nbin}.\\n\"\n",
    "        print(range_message)\n",
    "        \n",
    "        dummy_array = energy_axis.edges - energy_custom_range[0]\n",
    "        i_start_energy = np.argmin(np.abs(dummy_array.value))\n",
    "\n",
    "        dummy_array = energy_axis.edges - energy_custom_range[1]\n",
    "        i_stop_energy  = np.argmin(np.abs(dummy_array.value))\n",
    "\n",
    "        energy_axis = energy_axis.slice(slice(i_start_energy, i_stop_energy))\n",
    "\n",
    "        range_message = f\"Current  energy range: [{np.round(energy_axis.bounds[0].value,3)}, {np.round(energy_axis.bounds[1].value,3)}] \"\n",
    "        range_message+= str(energy_axis.unit)+f\". Energy bins: {energy_axis.nbin}.\\n\"\n",
    "        print(range_message)\n",
    "\n",
    "    return energy_axis\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Define_Effective_Area(name_file_fits,\n",
    "                          name_hdu,\n",
    "                          slice_energy = False,\n",
    "                          energy_range = None\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    Return the Effective Area as a function of True Energy with their unit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_file_fits: str\n",
    "        Name of a FITS file that must be opened to get the Energy Axis information.\n",
    "    name_hdu: str\n",
    "        Name of the HDU that contains the Energy Axis information.\n",
    "    slice_energy: bool\n",
    "        True if you want to work with a custom energy range.\n",
    "    energy_range: `astropy.units.Quantity`\n",
    "        A tuple with 2 values: start and stop of the requested true energy range.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `astropy.units.Quantity`\n",
    "    \n",
    "    \"\"\"\n",
    "    hdulist = fits.open(name_file_fits)\n",
    "    table = QTable.read( hdulist[name_hdu])\n",
    "    hdulist.close()\n",
    "    table['SPECRESP'] = table['SPECRESP'].to(u.cm**2)\n",
    "    \n",
    "    if slice_energy:\n",
    "        \n",
    "        edges = np.append(table['ENERG_LO'].value, table['ENERG_HI'].value[-1]) * table['ENERG_LO'].unit\n",
    "\n",
    "        dummy_array = edges - energy_range[0]\n",
    "        i_start = np.argmin(np.abs(dummy_array.value))\n",
    "\n",
    "        dummy_array = edges - energy_range[1]\n",
    "        i_stop  = np.argmin(np.abs(dummy_array.value))\n",
    "        \n",
    "        table = table[i_start: i_stop]\n",
    "\n",
    "    return table['SPECRESP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Define_Response_Matrix(name_file_fits,\n",
    "                           name_hdu,\n",
    "                           slice_energy      = False,\n",
    "                           energy_reco_range = None,\n",
    "                           energy_true_range = None\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    Return the Detector Response Matrix as a function of true and reconstructed energy with their unit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_file_fits: str\n",
    "        Name of a FITS file that must be opened to get the Energy Axis information.\n",
    "    name_hdu: str\n",
    "        Name of the HDU that contains the Energy Axis information.\n",
    "    slice_energy: bool\n",
    "        True if you want to work with a custom energy range.\n",
    "    energy_reco_range: `astropy.units.Quantity`\n",
    "        A tuple with 2 values: start and stop of the requested reconstructed energy range.\n",
    "    energy_true_range: `astropy.units.Quantity`\n",
    "        A tuple with 2 values: start and stop of the requested true energy range.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `astropy.units.Quantity`\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the Response\n",
    "    hdulist = fits.open(name_file_fits)\n",
    "    DRM_hdu = hdulist[name_hdu]\n",
    "    DRM_header = DRM_hdu.header\n",
    "    DRM_data = DRM_hdu.data\n",
    "    DRM_unit = u.Unit(\"\")#u.Unit(hdulist[name_hdu].header['TUNIT6'])\n",
    "\n",
    "    # Define the Matrix\n",
    "    DRM = np.zeros([len(DRM_data), DRM_header[\"DETCHANS\"]], dtype = np.float64)\n",
    "\n",
    "    for i, l in enumerate(DRM_data):\n",
    "        if l.field(\"N_GRP\"):\n",
    "            m_start = 0\n",
    "            for k in range(l.field(\"N_GRP\")):\n",
    "            \n",
    "                if np.isscalar(l.field(\"N_CHAN\")):\n",
    "                    f_chan = l.field(\"F_CHAN\")    #-1 # Should this be here?\n",
    "                    n_chan = l.field(\"N_CHAN\")\n",
    "                else:\n",
    "                    f_chan = l.field(\"F_CHAN\")[k] #-1 # Should this be here?\n",
    "                    n_chan = l.field(\"N_CHAN\")[k]\n",
    "\n",
    "                DRM[i, f_chan : f_chan+n_chan] = l.field(\"MATRIX\")[m_start : m_start+n_chan]\n",
    "                m_start += n_chan\n",
    "    \n",
    "    if slice_energy:\n",
    "        \n",
    "        edges_true = np.append(DRM_data.field('ENERG_LO'), DRM_data.field('ENERG_HI')[-1])\n",
    "        edges_true*= u.Unit(DRM_header['TUNIT1'])\n",
    "        \n",
    "        edges_reco = np.append(hdulist['EBOUNDS'].data.field('E_MIN'), hdulist['EBOUNDS'].data.field('E_MAX')[-1])\n",
    "        edges_reco*= u.Unit(hdulist['EBOUNDS'].header['TUNIT2'])\n",
    "        \n",
    "        # True\n",
    "        dummy_array = edges_true - energy_true_range[0]\n",
    "        i_start_energy_true = np.argmin(np.abs(dummy_array.value))\n",
    "\n",
    "        dummy_array = edges_true - energy_true_range[1]\n",
    "        i_stop_energy_true  = np.argmin(np.abs(dummy_array.value))\n",
    "        \n",
    "        # Reco\n",
    "        dummy_array = edges_reco - energy_reco_range[0]\n",
    "        i_start_energy_reco = np.argmin(np.abs(dummy_array.value))\n",
    "\n",
    "        dummy_array = edges_reco - energy_reco_range[1]\n",
    "        i_stop_energy_reco  = np.argmin(np.abs(dummy_array.value))\n",
    "        \n",
    "        # Slice        \n",
    "        DRM = DRM[i_start_energy_true:i_stop_energy_true, i_start_energy_reco:i_stop_energy_reco]\n",
    "        \n",
    "    hdulist.close()\n",
    "    \n",
    "    return DRM * DRM_unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Define_Background_Spectrum(name_file_bak,\n",
    "                               name_file_rmf,\n",
    "                               name_ebounds = 'EBOUNDS',\n",
    "                               name_spectrum = 'SPECTRUM',\n",
    "                               geometry = None,\n",
    "                               energy_unit = u.keV,\n",
    "                               time_unit = u.s,\n",
    "                               slice_energy = False,\n",
    "                               energy_reco_range = None\n",
    "                              ):\n",
    "    \"\"\"\n",
    "    Return the background Spectral Model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_file_fits: str\n",
    "        Name of a FITS file that must be opened to get the Energy Axis information.\n",
    "    name_hdu: str\n",
    "        Name of the HDU that contains the Energy Axis information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `astropy.units.Quantity`\n",
    "    \"\"\"\n",
    "    \n",
    "    hdulist_rmf = fits.open(name_file_rmf)\n",
    "    hdulist_bak = fits.open(name_file_bak)\n",
    "    \n",
    "    # Define the Background Tables\n",
    "    table_ebounds = QTable.read( hdulist_rmf[name_ebounds ] )\n",
    "    table_spectrum= QTable.read( hdulist_bak[name_spectrum] )  \n",
    "    \n",
    "    if table_ebounds['E_MIN'].unit is None:\n",
    "        table_ebounds['E_MIN'] = table_ebounds['E_MIN'] * energy_unit\n",
    "        table_ebounds['E_MAX'] = table_ebounds['E_MAX'] * energy_unit\n",
    "        \n",
    "    # Merge Tables\n",
    "    table = QTable()\n",
    "    \n",
    "    table['CHANNEL'] = table_ebounds['CHANNEL']\n",
    "    table['E_MIN'  ] = table_ebounds['E_MIN'  ]\n",
    "    table['E_MAX'  ] = table_ebounds['E_MAX'  ]\n",
    "    table['RATE'   ] = table_spectrum['COUNTS'].value / ( hdulist_bak['SPECTRUM'].header['EXPOSURE']*u.s)    \n",
    "    table['BKG_MOD'] = table['RATE'] / (table['E_MAX']-table['E_MIN'])\n",
    "    table['BKG_MOD'] = table['BKG_MOD']/ geometry.solid_angle()\n",
    "    \n",
    "    if slice_energy:\n",
    "        \n",
    "        edges = np.append(table['E_MIN'].value, table['E_MAX'].value[-1]) * table['E_MIN'].unit\n",
    "\n",
    "        dummy_array = edges - energy_reco_range[0]\n",
    "        i_start_energy_reco = np.argmin(np.abs(dummy_array.value))\n",
    "\n",
    "        dummy_array = edges - energy_reco_range[1]\n",
    "        i_stop_energy_reco  = np.argmin(np.abs(dummy_array.value))\n",
    "        \n",
    "        table = table[i_start_energy_reco: i_stop_energy_reco]\n",
    "        \n",
    "    hdulist_rmf.close()\n",
    "    hdulist_bak.close()\n",
    "        \n",
    "    \n",
    "    return table['BKG_MOD']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd466cd5",
   "metadata": {},
   "source": [
    "## 0 - Setup: Define YAML file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_file = \"/home/gabriele/Documents/gammapy/LCsim/Input/GRB160530A_COSI_bal_200ms_250_10000_keV.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"/home/gabriele/Documents/gammapy/LCsim/Input/GRB160530A_COSI_bal_200ms_250_10000_keV.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebeec28",
   "metadata": {},
   "source": [
    "# 1 - Load the YAML file and define the input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f223596",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(yaml_file) as f:\n",
    "    data = yaml.load(f, Loader = SafeLoader)\n",
    "###############################################################\n",
    "\n",
    "\n",
    "# Transient Information\n",
    "Name_transient = data['Name_GRB']\n",
    "Name_instrument= data['Name_instrument']\n",
    "Name_detector  = data['Name_detector']\n",
    "\n",
    "\n",
    "# Input Files\n",
    "File_bak = data['Input_bak']\n",
    "File_rmf = data['Input_rmf']\n",
    "File_arf = data['Input_arf']\n",
    "File_gbm = data['Input_gbm']\n",
    "File_lightcurve = data['Input_lightcurve']\n",
    "\n",
    "\n",
    "# Energy Axes Parameters\n",
    "Energy_interpolation = data['Energy_interpolation']\n",
    "Energy_slice = data['Energy_slice']\n",
    "Energy_unit = u.Unit(data[\"Energy_unit\"])\n",
    "\n",
    "custom_range_energy_reco = tuple(data['Energy_range_reco']) * Energy_unit\n",
    "custom_range_energy_true = tuple(data['Energy_range_true']) * Energy_unit\n",
    "\n",
    "\n",
    "# Observation Parameters\n",
    "Number_of_LightCurves = data['N_light_curves']\n",
    "Time_unit = u.Unit(data['Time_unit'])\n",
    "\n",
    "t_start_obs= data['Observation_time_start'] * Time_unit\n",
    "t_stop_obs = data['Observation_time_stop' ] * Time_unit\n",
    "live_t_obs = data['Observation_livetimes' ] * Time_unit\n",
    "dead_times = data['Observation_deadtimes' ] * Time_unit\n",
    "\n",
    "\n",
    "# Spectral fit time range and parameters\n",
    "spectral_fit_time_range = data['Specfit_time_range'] * Time_unit\n",
    "\n",
    "GBM_Ampli = data['Specfit_amplitude'] * u.Unit(data['Specfit_amplitude_unit'])\n",
    "GBM_Index = data['Specfit_index'] * u.Unit(\"\")\n",
    "GBM_Epeak = data['Specfit_epeak'] * Energy_unit\n",
    "GBM_Erefe = data['Specfit_erefe'] * Energy_unit\n",
    "\n",
    "\n",
    "# Create Output Directory\n",
    "\n",
    "output_directory = data['Output_directory']\n",
    "output_directory+= Name_transient + '/'\n",
    "output_directory+= Name_instrument + '_' + Name_detector + '_'\n",
    "output_directory+= str(int(live_t_obs.to('ms').value)) + 'ms_'\n",
    "output_directory+= str(int(custom_range_energy_reco.value[0])) + '_'\n",
    "output_directory+= str(int(custom_range_energy_reco.value[1])) + '_'\n",
    "output_directory+= Energy_unit.to_string()+'/'\n",
    "\n",
    "if data['Output_run_id'] is not None:\n",
    "    output_directory += data['Output_run_id']+'/'\n",
    "\n",
    "os.makedirs(os.path.dirname(output_directory), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aec221",
   "metadata": {},
   "source": [
    "# 2 - Define Reference System\n",
    "\n",
    "Define Reference Time.\n",
    "\n",
    "Define Pointing Direction.\n",
    "\n",
    "Define Instrument FoV axes: Offset, Lon, Lat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27034368",
   "metadata": {},
   "source": [
    "#### 2.1 - Define the Reference Time of the simulated observations as the Trigger Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78697071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trigger Time as the Reference Time of the simulated observations\n",
    "trigger_time_t0 = Define_Reference_Time(File_gbm)\n",
    "\n",
    "# Define preferred time format\n",
    "TimeMapAxis.time_format = \"iso\" \n",
    "trigger_time_t0.format = TimeMapAxis.time_format\n",
    "\n",
    "# Print\n",
    "trigger_time_t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb675b4",
   "metadata": {},
   "source": [
    "#### 2.2 - Define the Pointing Direction of the simulated observations and the FoV (Lon, Lat, Offset) axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fe9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the (RA_OBJ, DEC_OBJ) coordinates as the Pointing Direction of the simulated observations\n",
    "pointing = Define_Pointing_Direction(File_gbm)\n",
    "\n",
    "# Print\n",
    "pointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f509cc3",
   "metadata": {},
   "source": [
    "**Define Instrument FoV Axes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: The FoV Center is (0,0), FoV_Lon and FoV_Lat are symmetric wrt to 0.0\n",
    "\n",
    "fov_maximum_offset = 5.0 * u.deg\n",
    "fov_n_bin = 5\n",
    "\n",
    "# Create Offset axis\n",
    "axis_offset = MapAxis.from_bounds(0.0, fov_maximum_offset.value,\n",
    "                                  unit = fov_maximum_offset.unit, nbin = fov_n_bin, name = \"offset\"\n",
    "                                 )\n",
    "# Create Instrument FoV_lon axis\n",
    "axis_fovlon = MapAxis.from_bounds(-fov_maximum_offset.value/2.0, +fov_maximum_offset.value/2.0,\n",
    "                                  unit = fov_maximum_offset.unit, nbin = fov_n_bin, name = \"fov_lon\"\n",
    "                                 )\n",
    "# Create Instrument FoV_lat axis\n",
    "axis_fovlat = MapAxis.from_bounds(-fov_maximum_offset.value/2.0, +fov_maximum_offset.value/2.0,\n",
    "                                  unit = fov_maximum_offset.unit, nbin = fov_n_bin, name = \"fov_lat\"\n",
    "                                 )\n",
    "\n",
    "# Print\n",
    "print(axis_offset)\n",
    "print(axis_fovlon)\n",
    "print(axis_fovlat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c88a8",
   "metadata": {},
   "source": [
    "#### 2.3 - Define Observation Starting Times and Livetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7664467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Number of observations\n",
    "n_obs = (t_stop_obs-t_start_obs)/live_t_obs\n",
    "n_obs = int(np.floor(n_obs.value))\n",
    "\n",
    "# Define starting time of each observation linearly spaced during the night\n",
    "starting_times = np.linspace(t_start_obs.value,\n",
    "                             t_stop_obs.value,\n",
    "                             num = n_obs\n",
    "                            )\n",
    "starting_times = starting_times.tolist() * Time_unit\n",
    "\n",
    "# Define the duration of each observation as the difference between two following starting times\n",
    "# minus the rest time between them.\n",
    "livetimes = starting_times[1:] - starting_times[:-1] - dead_times\n",
    "\n",
    "# Remove last edge to have the same array dimesion for starting times and livetimes.\n",
    "starting_times = starting_times[:-1]\n",
    "\n",
    "# Turn them from astropy.units.quantity.Quantity to astropy.time.core.Time with t_ref\n",
    "starting_times = Time(trigger_time_t0 + starting_times)\n",
    "\n",
    "# Adjust n_obs\n",
    "n_obs = starting_times.size\n",
    "\n",
    "print(n_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f35f2",
   "metadata": {},
   "source": [
    "#### 2.4 - Load Empirical Light Curve and slice to observation time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Table with the empirical lightcurve\n",
    "LC_empirical = QTable.read(File_lightcurve, format = 'fits')\n",
    "\n",
    "\n",
    "# Let's find the time points of the Empirical Light Curve closest to start and stop of observations. \n",
    "LC_emp_i_start= np.argmin(np.abs(LC_empirical['time'].value - t_start_obs.value))\n",
    "LC_emp_i_stop = np.argmin(np.abs(LC_empirical['time'].value - t_stop_obs.value ))\n",
    "\n",
    "LC_emp = LC_empirical[LC_emp_i_start:LC_emp_i_stop]\n",
    "\n",
    "# Empirical Light Curve Data for plot\n",
    "\n",
    "# Time\n",
    "LCe_time_val = LC_emp['time'      ].value\n",
    "LCe_time_wid = LC_emp['time_width'].value\n",
    "\n",
    "# Count rates\n",
    "LCe_cnt_rate = LC_emp['cnt_rt'    ].value\n",
    "LCe_cnt_erro = LC_emp['cnt_rt_err'].value\n",
    "\n",
    "# Background rates\n",
    "LCe_bkg_rate = LC_emp['bkg_rt'    ].value\n",
    "LCe_bkg_erro = LC_emp['bkg_rt_err'].value\n",
    "\n",
    "# Excess rates\n",
    "LCe_exc_rate = LCe_cnt_rate - LCe_bkg_rate\n",
    "LCe_exc_erro = LCe_cnt_erro + LCe_bkg_erro\n",
    "\n",
    "# Model: best fit excess rates\n",
    "LCe_exc_pred = LC_emp['best_model'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524e726",
   "metadata": {},
   "source": [
    "## 3 - Define the Detector Response\n",
    "\n",
    "Define True and Reconstructed Energy Axes.\n",
    "\n",
    "Load the Detector Response Matrix.\n",
    "\n",
    "Define the Effective Area.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ec7ac",
   "metadata": {},
   "source": [
    "#### 3.1 - Define the True and Reconstructed Energy Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8511a",
   "metadata": {},
   "source": [
    "The Reconstructed Energy Axis is defined from the EBOUNDS hdu of the response file.\n",
    "\n",
    "The True Energy Axis is defined from the SPECRESP MATRIX hdu of the response file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a870896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Reconstructed Energy Axis\n",
    "\n",
    "print(\"Reconstructed Energy Axis\\n\")\n",
    "axis_energy_reco = Define_Energy_Axis(File_rmf,\n",
    "                                      \"EBOUNDS\",\n",
    "                                      energy_is_true = False,\n",
    "                                      interpolation_mode = Energy_interpolation,\n",
    "                                      slice_energy = Energy_slice,\n",
    "                                      energy_custom_range = custom_range_energy_reco\n",
    "                                     )\n",
    "\n",
    "print(\"\\nTrue Energy Axis\\n\")\n",
    "axis_energy_true = Define_Energy_Axis(File_rmf,\n",
    "                                      \"MATRIX\",\n",
    "                                      energy_is_true = True,\n",
    "                                      interpolation_mode = Energy_interpolation,\n",
    "                                      slice_energy = Energy_slice,\n",
    "                                      energy_custom_range = custom_range_energy_true\n",
    "                                     )\n",
    "\n",
    "# Print\n",
    "print(axis_energy_reco)\n",
    "print(axis_energy_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62af1c3",
   "metadata": {},
   "source": [
    "#### 3.2 - Define Source Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea00028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Source Geometry: a region in the sky where the source is placed.\n",
    "\n",
    "geometry_radius = 1.0 * u.deg\n",
    "\n",
    "source_geometry_str = pointing.frame.name + ';circle('\n",
    "source_geometry_str+= pointing.to_string().split()[0] + ', '\n",
    "source_geometry_str+= pointing.to_string().split()[1] + ', '\n",
    "source_geometry_str+= str(geometry_radius.value) + ')'\n",
    "\n",
    "geom = RegionGeom.create(source_geometry_str, axes = [axis_energy_reco])\n",
    "\n",
    "# Print\n",
    "print(geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebc587",
   "metadata": {},
   "source": [
    "#### 3.3 - Define the Effective Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Effective Area array (as a function of True Energy)\n",
    "aeff_array = Define_Effective_Area(File_arf,\n",
    "                      \"SPECRESP\",\n",
    "                      slice_energy = Energy_slice,\n",
    "                      energy_range = custom_range_energy_true\n",
    "                     )\n",
    "\n",
    "# Compute Effective Area matrix (as a function of True Energy and Offset)\n",
    "aeff_matrix = np.ndarray( (axis_energy_true.nbin, axis_offset.nbin) )\n",
    "\n",
    "for i in range(axis_offset.nbin):\n",
    "    aeff_matrix.transpose()[i] = aeff_array\n",
    "\n",
    "# Instantiate Effective Area object\n",
    "aeff = EffectiveAreaTable2D(axes = [axis_energy_true, axis_offset],\n",
    "                            data = aeff_matrix,\n",
    "                            unit = aeff_array.unit\n",
    "                            # meta = metadata dictionary from header\n",
    "                           )\n",
    "# Print\n",
    "print(aeff)\n",
    "print(f\"Total effective area: {np.sum(aeff_array)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646265f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save\n",
    "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "axs[0].step(axis_energy_true.center.value, aeff_array, c='C3')\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel('True Energy ['+axis_energy_true.unit.to_string()+']', fontsize = 'large')\n",
    "axs[0].set_ylabel('Effective Area ['+aeff.unit.to_string()+']', fontsize = 'large')\n",
    "axs[0].set_title(\"Effective Area \"+Name_instrument+\" \"+Name_detector+\", \"+Name_transient+\".\", fontsize = 'large')\n",
    "axs[0].grid()\n",
    "\n",
    "aeff.plot(ax = axs[1], add_cbar = True)\n",
    "axs[1].set_title(\"Effective Area \"+Name_instrument+\" \"+Name_detector+\", \"+Name_transient+\".\", fontsize = 'large')\n",
    "axs[1].set_xscale('log')\n",
    "\n",
    "fig.savefig(output_directory + \"IRF_effective_area.png\",\n",
    "            facecolor = 'white'\n",
    "           )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed18706",
   "metadata": {},
   "source": [
    "#### 3.4 - Load the Spectral Response Matrix\n",
    "\n",
    "The Matrix is defined from the SPECRESP MATRIX hdu of the response file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRM_quantity = Define_Response_Matrix(File_rmf,\n",
    "                                      \"MATRIX\",\n",
    "                                      slice_energy      = True,\n",
    "                                      energy_reco_range = custom_range_energy_reco,\n",
    "                                      energy_true_range = custom_range_energy_true\n",
    "                                     )\n",
    "DRM_quantity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd481c19",
   "metadata": {},
   "source": [
    "#### 3.5 - Define Energy Dispersion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a95a47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build Kernel\n",
    "edisp = EDispKernel(axes = [axis_energy_true, axis_energy_reco], data = DRM_quantity.value)\n",
    "\n",
    "# Build EDispKernelMap\n",
    "edisp = EDispKernelMap.from_edisp_kernel(edisp, geom = geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Normalization\n",
    "# for r in edisp.edisp_map.data.T[0][0].T:\n",
    "#     print(len(r), np.sum(r))\n",
    "\n",
    "# # Peek\n",
    "# edisp.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f65f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correct Units for exposure map\n",
    "edisp.exposure_map = edisp.exposure_map.to_unit(aeff.unit * Time_unit)\n",
    "\n",
    "# Initialize the Exposure with effective area values * livetimes. Assume all lifetimes are equal\n",
    "edisp.exposure_map.data *= 0.0\n",
    "edisp.exposure_map.data += np.reshape( aeff.data.T[0], edisp.exposure_map.data.T.shape ).T\n",
    "edisp.exposure_map.data *= livetimes[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Grid\n",
    "X, Y = np.meshgrid(axis_energy_true.center.value, axis_energy_reco.center.value)\n",
    "\n",
    "# Copy Data with Masking\n",
    "Z = np.ma.masked_where(edisp.edisp_map.data.T[0][0] <= 0, edisp.edisp_map.data.T[0][0])\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, figsize=(9,5))\n",
    "\n",
    "# Define Levels\n",
    "levs = np.linspace(np.floor(np.power(Z.min(),0.3)),\n",
    "                   np.ceil( np.power(Z.max(),0.3)),\n",
    "                   num = 50\n",
    "                  )\n",
    "levs = np.power(levs, 1.0/0.3)\n",
    "\n",
    "# Plot Data\n",
    "cs = ax.contourf(X, Y, Z, levs, norm = PowerNorm(gamma=0.3), cmap = 'plasma')\n",
    "ax.contour(X, Y, Z, levs, norm = PowerNorm(gamma=0.3), colors='white', alpha=0.05)\n",
    "cbar = fig.colorbar(cs)\n",
    "\n",
    "# Labels\n",
    "ax.set_facecolor('k')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "cbar.set_label('Redistribution Probability', fontsize = 'large')\n",
    "ax.set_xlabel('True Energy ['+axis_energy_true.unit.to_string()+']', fontsize = 'large')\n",
    "ax.set_ylabel('Energy ['     +axis_energy_reco.unit.to_string()+']', fontsize = 'large')\n",
    "ax.set_title(\"Energy Dispersion Matrix \"+Name_instrument+\" \"+Name_detector+\", \"+Name_transient+\".\",\n",
    "             fontsize = 'large'\n",
    "            )\n",
    "\n",
    "# Save figure\n",
    "fig.savefig(output_directory + \"IRF_energy_dispersion_matrix.png\",\n",
    "            facecolor = 'white'\n",
    "           )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0977b59",
   "metadata": {},
   "source": [
    "#### Define Energy Dispersion from a gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ddea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build Gaussian Kernel\n",
    "# edisp_gauss = EDispKernel.from_gauss(energy_axis_true = axis_energy_true,\n",
    "#                                      energy_axis      = axis_energy_reco,\n",
    "#                                      bias             = 0,\n",
    "#                                      sigma            = 0.1\n",
    "#                                     )\n",
    "# # Build Gaussian EDispKernelMap\n",
    "# edisp_gauss = EDispKernelMap.from_edisp_kernel(edisp_gauss, geom = geom)\n",
    "\n",
    "# # Peek\n",
    "# edisp_gauss.peek()\n",
    "\n",
    "# # Check normalization\n",
    "# for r in edisp_gauss.edisp_map.data.T[0][0].T:\n",
    "#     print(len(r), np.sum(r))\n",
    "\n",
    "\n",
    "# # Set correct Units for exposure map\n",
    "# edisp_gauss.exposure_map = edisp_gauss.exposure_map.to_unit(aeff.unit * Time_unit)\n",
    "\n",
    "# # Initialize the Exposure with effective area values * livetimes. Assume all lifetimes are equal\n",
    "# edisp_gauss.exposure_map.data += np.reshape(aeff.data.T[0], (1,1,1,80)).T\n",
    "# edisp_gauss.exposure_map.data *= livetimes[0].value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddd5c7",
   "metadata": {},
   "source": [
    "## 4 - Define the Background Spectral Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d83041",
   "metadata": {},
   "source": [
    "Define appropriate reco energy axis and slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2216e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Background\n",
    "bak_model = Define_Background_Spectrum(File_bak,\n",
    "                                       File_rmf,\n",
    "                                       name_ebounds = 'EBOUNDS',\n",
    "                                       name_spectrum = 'SPECTRUM',\n",
    "                                       geometry = geom,\n",
    "                                       energy_unit = Energy_unit,\n",
    "                                       time_unit = Time_unit,\n",
    "                                       slice_energy = Energy_slice,\n",
    "                                       energy_reco_range = custom_range_energy_reco\n",
    "                                      )\n",
    "\n",
    "# Prepare Background Matrix (as a function of energy, lon and lat) as ndarray\n",
    "data_bkg = np.ndarray( (axis_energy_reco.nbin, axis_fovlon.nbin, axis_fovlat.nbin) )\n",
    "\n",
    "for i in range(axis_fovlat.nbin):\n",
    "    for j in range(axis_fovlon.nbin):\n",
    "        data_bkg.transpose()[i][j] = bak_model.value\n",
    "\n",
    "# Instantiate Background object # I should add meta=metadata dictionary from header    \n",
    "bkg = Background3D(axes = [axis_energy_reco, axis_fovlon, axis_fovlat],\n",
    "                   data = data_bkg,\n",
    "                   unit = bak_model.unit,\n",
    "                   #is_pointlike = False,\n",
    "                   #fov_alignment = FoVAlignment.RADEC,\n",
    "                   #meta = None,\n",
    "                   #interp_kwargs = None\n",
    "                   )\n",
    "\n",
    "# Print\n",
    "print(bkg)\n",
    "# bkg.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a81380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save\n",
    "fig, ax = plt.subplots(1, figsize=(7,5))\n",
    "\n",
    "bak_to_plot = bak_model*geom.solid_angle()\n",
    "ax.step(axis_energy_reco.center.value,\n",
    "        bak_to_plot,\n",
    "        color = 'C3'\n",
    "       )\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Energy [\"+axis_energy_reco.unit.to_string()+\"]\", fontsize = 'large')\n",
    "ax.set_ylabel(\"Background rate [\"+bak_to_plot.unit.to_string()+\"]\", fontsize = 'large')\n",
    "ax.set_title(\"Background Spectral Model \"+Name_instrument+\" \"+Name_detector+\", \"+Name_transient+\".\",\n",
    "             fontsize = 'large'\n",
    "            )\n",
    "ax.grid()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig(output_directory + \"IRF_background_spectrum.png\",\n",
    "            facecolor = 'white'\n",
    "           )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9050b",
   "metadata": {},
   "source": [
    "### Define the IRFs dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "IRFs = {'aeff' : aeff,\n",
    "        'bkg'  : bkg\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690f18b",
   "metadata": {},
   "source": [
    "## 5 - Define Temporal and Spectral Model for the simulated source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal model\n",
    "Temporal_Model_Table_Metadata = {'MJDREFI' : int(np.modf(trigger_time_t0.mjd)[1]),\n",
    "                                 'MJDREFF' :     np.modf(trigger_time_t0.mjd)[0],\n",
    "                                 'TIMEUNIT': LC_empirical['time'].unit.to_string(),\n",
    "                                 'TIMESYS' : trigger_time_t0.scale\n",
    "                                }\n",
    "\n",
    "Temporal_Model_Table = Table(meta = Temporal_Model_Table_Metadata)\n",
    "Temporal_Model_Table['TIME'] = LC_empirical['time']\n",
    "Temporal_Model_Table['NORM'] = LC_empirical['norm']\n",
    "\n",
    "Temporal_Model = LightCurveTemplateTemporalModel(Temporal_Model_Table)\n",
    "\n",
    "# Print\n",
    "print(Temporal_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2102e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Temporal model at maximum, should return 1\n",
    "# print(temporal_model.evaluate(trigger_time_t0.mjd+0.075/86400.0))\n",
    "\n",
    "# Evaluate correction factor\n",
    "correction_factor = [trigger_time_t0.mjd + spectral_fit_time_range[0].to(\"day\").value,\n",
    "                     trigger_time_t0.mjd + spectral_fit_time_range[1].to(\"day\").value\n",
    "                    ]\n",
    "correction_factor = Time(correction_factor, format = 'mjd')\n",
    "\n",
    "correction_factor = Temporal_Model.integral(correction_factor[0], correction_factor[1])\n",
    "print(correction_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eece78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral model\n",
    "Spectral_Model = ExpCutoffPowerLawSpectralModel(amplitude = GBM_Ampli / correction_factor,\n",
    "                                                index     = - GBM_Index,\n",
    "                                                lambda_   = (2.0 + GBM_Index ) / GBM_Epeak,\n",
    "                                                reference = GBM_Erefe\n",
    "                                               )\n",
    "# Print\n",
    "print(Spectral_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Source Model = Temporal & Spectral\n",
    "model_simu = SkyModel(spectral_model = Spectral_Model,\n",
    "                      temporal_model = Temporal_Model,\n",
    "                      name           = \"Compt-Empirical\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and Save\n",
    "fig, axs = plt.subplots(1,2, figsize = (15,5) )\n",
    "\n",
    "# Spectral Model\n",
    "if Energy_interpolation == 'lin':\n",
    "    energies_to_plot = np.linspace(axis_energy_true.edges[0], axis_energy_true.edges[-1], num=100)\n",
    "elif Energy_interpolation == 'log':\n",
    "    energies_to_plot = np.linspace(np.log10(axis_energy_true.edges[0].value),\n",
    "                                   np.log10(axis_energy_true.edges[-1].value),\n",
    "                                   num = 100\n",
    "                                  )\n",
    "    energies_to_plot = np.power(10,energies_to_plot)\n",
    "    energies_to_plot = energies_to_plot * axis_energy_true.unit\n",
    "\n",
    "dnde_to_plot = Spectral_Model.evaluate(energies_to_plot,\n",
    "                                       Spectral_Model.parameters.value[0]*Spectral_Model.parameters[0].unit,\n",
    "                                       Spectral_Model.parameters.value[1]*Spectral_Model.parameters[1].unit,\n",
    "                                       Spectral_Model.parameters.value[2]*Spectral_Model.parameters[2].unit,\n",
    "                                       Spectral_Model.parameters.value[3]*Spectral_Model.parameters[3].unit,\n",
    "                                       Spectral_Model.parameters.value[4]*Spectral_Model.parameters[4].unit\n",
    "                                      )\n",
    "\n",
    "axs[0].plot(energies_to_plot.value, dnde_to_plot.value)\n",
    "\n",
    "axs[0].set_title(\"Spectral Model \"+Name_transient+\", \"+Name_instrument+\" \"+Name_detector+\".\", fontsize = 'large')\n",
    "axs[0].set_xlabel(\"True Energy [\"+energies_to_plot.unit.to_string()+\"]\", fontsize = 'large')\n",
    "axs[0].set_ylabel(\"dnde [\"+dnde_to_plot.unit.to_string()+\"]\", fontsize = 'large')\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].grid(which=\"both\")\n",
    "\n",
    "# Temporal Model\n",
    "\n",
    "times_to_plot = np.linspace(t_start_obs, t_stop_obs, num=300)\n",
    "norms_to_plot = Temporal_Model.evaluate(trigger_time_t0.mjd + times_to_plot.to(\"day\").value)\n",
    "axs[1].plot(times_to_plot.value, norms_to_plot)\n",
    "axs[1].set_title(\"Temporal Model \"+Name_transient+\", \"+Name_instrument+\" \"+Name_detector+\".\", fontsize = 'large')\n",
    "axs[1].grid(which=\"both\")\n",
    "axs[1].set_xlabel(\"Time since Trigger [\"+Time_unit.to_string()+\"]\", fontsize = 'large')\n",
    "axs[1].set_ylabel(\"Temporal Model Norm [A.U.]\", fontsize = 'large')\n",
    "\n",
    "# Legends\n",
    "labels = []\n",
    "handles = []\n",
    "for par in Spectral_Model.parameters:\n",
    "    labels.append(par.name+f\": {par.value:.2e} [\" +par.unit.to_string()+\"]\")\n",
    "    handles.append(mlines.Line2D([], []))\n",
    "    \n",
    "axs[0].legend(handles, labels)\n",
    "axs[1].legend([mlines.Line2D([], []),mlines.Line2D([], [])],\n",
    "              [\"Trigger: \"+trigger_time_t0.value,f\"Correction Factor: {correction_factor:.2f}\"])\n",
    "\n",
    "# Save Figure\n",
    "fig.savefig(output_directory + \"Models.png\",\n",
    "            facecolor = 'white'\n",
    "           )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_simu.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5eb572",
   "metadata": {},
   "source": [
    "# 6 - Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08bf1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a List of Datasets, each will be a Light curve\n",
    "List_of_Datasets = []\n",
    "# Fill it with empty Datasets\n",
    "for i_LC in range(Number_of_LightCurves):\n",
    "    List_of_Datasets.append(Datasets())\n",
    "    \n",
    "    \n",
    "# Create an empty SpectrumDataset object to host geometry and energy info.\n",
    "empty = SpectrumDataset.create(geom = geom,\n",
    "                               energy_axis_true = axis_energy_true,\n",
    "                               name = \"empty\",\n",
    "                               edisp = edisp\n",
    "                              )\n",
    "\n",
    "# Create Maker object.\n",
    "# containment_correction must be set True if I have a PSF, to adapt the\n",
    "# exposure map and account for PSF broadening and the PSF containment.\n",
    "maker = SpectrumDatasetMaker(selection = [\"exposure\",\n",
    "                                          \"background\"\n",
    "                                         ],\n",
    "                             containment_correction = False\n",
    "                            )\n",
    "\n",
    "# This mock light curve will store info on the predicted background and excess rates.\n",
    "# It won't contain any simulation.\n",
    "datasets_generic = Datasets()\n",
    "\n",
    "for idx in range(n_obs):\n",
    "    print(f'Creating Dataset {idx+1}/{n_obs}...             \\r', end = '')\n",
    "    \n",
    "    # Set the current observation. Observations differ only in their starting time.\n",
    "    obs = Observation.create(pointing      = pointing,\n",
    "                             livetime      = livetimes[idx],\n",
    "                             tstart        = starting_times[idx],\n",
    "                             irfs          = IRFs,\n",
    "                             reference_time= trigger_time_t0,\n",
    "                             obs_id        = idx\n",
    "                            )\n",
    "    \n",
    "    # Set name according to observation number. Set geometry and energy information.\n",
    "    dataset_generic = empty.copy(name = f\"dataset-{idx}\")\n",
    "    \n",
    "    # Run: creates the SpectrumDataset. It also sets the Background counts.\n",
    "    dataset_generic = maker.run(dataset_generic, obs)\n",
    "    \n",
    "    # Set the Energy Disperison    \n",
    "    dataset_generic.edisp = edisp\n",
    "    \n",
    "    # Set the source model and compute the predicted excess counts from it.\n",
    "    dataset_generic.models = model_simu\n",
    "    \n",
    "    # For this observation simulate background and counts for each different light curve\n",
    "    for i_LC in range(Number_of_LightCurves):\n",
    "               \n",
    "        dataset = dataset_generic.copy(name = f\"LC-{i_LC}\"+f\"--Dataset-{idx}\")\n",
    "        \n",
    "        # Set models, that CANNOT BE COPIED\n",
    "        dataset.models = model_simu\n",
    "        \n",
    "#        # Introduce Background Fluctuations.\n",
    "#         random_state = get_random_state('random-seed')\n",
    "#         data = np.nan_to_num(dataset.npred_background().data,\n",
    "#                              copy = True, nan = 0.0, posinf = 0.0, neginf = 0.0)\n",
    "#         data = random_state.poisson(data)\n",
    "#         dataset.npred_background().data = data\n",
    "#         dataset.background = dataset.npred_background()\n",
    "        \n",
    "        # Simulate counts from Poisson(avg=Predicted Backgrounds+Predicted count excess)\n",
    "        dataset.fake()\n",
    "        \n",
    "        # Add this dataset to the right collection.\n",
    "        datasets = List_of_Datasets[i_LC]\n",
    "        datasets.append(dataset)\n",
    "    \n",
    "    \n",
    "    datasets_generic.append(dataset_generic)\n",
    "    \n",
    "        \n",
    "    # Repeat for a new observation.\n",
    "    \n",
    "# Loop ended.\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86603001",
   "metadata": {},
   "source": [
    "# 7 - Plot and explore results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa98cf",
   "metadata": {},
   "source": [
    "The model and background information can be seen in the *generic* datasets, where counts have not been faked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quicklook_table_generic = datasets_generic.info_table()\n",
    "\n",
    "print('Columns available:\\n', quicklook_table_generic.keys())\n",
    "\n",
    "show_columns = ['name',\n",
    "                'background',\n",
    "                'npred_signal',\n",
    "                'npred',\n",
    "                'counts',              \n",
    "                'livetime',\n",
    "                'counts_rate',\n",
    "                'background_rate',\n",
    "                'excess_rate'\n",
    "               ]\n",
    "quicklook_table_generic[show_columns][54:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d92cc",
   "metadata": {},
   "source": [
    "Quick look to a Light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "quicklook_table = List_of_Datasets[0].info_table()\n",
    "\n",
    "print('Columns available:\\n',quicklook_table.keys())\n",
    "\n",
    "show_columns = ['name',\n",
    "                'background',\n",
    "                'npred_signal',\n",
    "                'npred',\n",
    "                'counts',              \n",
    "                'livetime',\n",
    "                'counts_rate',\n",
    "                'background_rate',\n",
    "                'excess_rate'\n",
    "               ]\n",
    "quicklook_table[show_columns][54:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12456e0c",
   "metadata": {},
   "source": [
    "Average quantities of the Light Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ddd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = Number_of_LightCurves\n",
    "n_cols = n_obs\n",
    "    \n",
    "SIM_matrix_cnt_rate = np.empty( (n_rows, n_cols) )\n",
    "SIM_matrix_bkg_rate = np.empty( (n_rows, n_cols) )\n",
    "\n",
    "print('Extracting rates from table...')\n",
    "for i in range(n_rows):\n",
    "    table_i = List_of_Datasets[i].info_table()\n",
    "    SIM_matrix_cnt_rate[i] = table_i['counts_rate'    ].value\n",
    "    SIM_matrix_bkg_rate[i] = table_i['background_rate'].value\n",
    "\n",
    "print('Computing averages...')\n",
    "# Count rates\n",
    "AVG_cnt_rate = np.mean(SIM_matrix_cnt_rate, axis = 0)\n",
    "AVG_cnt_erro = np.std( SIM_matrix_cnt_rate, axis = 0, ddof = 1)\n",
    "        \n",
    "# Background rates    \n",
    "AVG_bkg_rate = np.mean(SIM_matrix_bkg_rate, axis = 0)\n",
    "AVG_bkg_erro = np.std( SIM_matrix_bkg_rate, axis = 0, ddof = 1)\n",
    "        \n",
    "# Excess Rates\n",
    "AVG_exc_rate = AVG_cnt_rate - AVG_bkg_rate\n",
    "AVG_exc_erro = np.std( SIM_matrix_cnt_rate - SIM_matrix_bkg_rate, axis = 0, ddof = 1)\n",
    "        \n",
    "# Predicted Signal Rates and Predicted background\n",
    "AVG_exc_pred = datasets_generic.info_table()['npred_signal'].value / livetimes.value\n",
    "AVG_bkg_pred = datasets_generic.info_table()['background_rate'].value\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_light_curve(avg, figsize = (15.0, 22.0),curve_index = 0, save_figures_directory = None):\n",
    "    \n",
    "    # Time\n",
    "    SIM_time_val = starting_times + livetimes / 2.0 - trigger_time_t0\n",
    "    SIM_time_val = SIM_time_val.sec\n",
    "    SIM_time_wid = livetimes.value\n",
    "    \n",
    "    if avg:\n",
    "        # Count rates\n",
    "        SIM_cnt_rate = AVG_cnt_rate\n",
    "        SIM_cnt_erro = AVG_cnt_erro\n",
    "        \n",
    "        # Background rates    \n",
    "        SIM_bkg_rate = AVG_bkg_rate\n",
    "        SIM_bkg_erro = AVG_bkg_erro\n",
    "        \n",
    "        # Excess Rates\n",
    "        SIM_exc_rate = AVG_exc_rate\n",
    "        SIM_exc_erro = AVG_exc_erro\n",
    "        \n",
    "        # Predicted Signal Rates\n",
    "        SIM_exc_pred = AVG_exc_pred\n",
    "    \n",
    "    else:\n",
    "        # Choose one Light Curve\n",
    "        datasets = List_of_Datasets[curve_index].info_table()\n",
    "        \n",
    "        # Count rates\n",
    "        SIM_cnt_rate = datasets['counts_rate'].value\n",
    "        SIM_cnt_erro = SIM_cnt_rate / np.sqrt(datasets['counts'].value)\n",
    "        \n",
    "        # Background rates    \n",
    "        SIM_bkg_rate = datasets['background_rate'].value\n",
    "        SIM_bkg_erro = SIM_bkg_rate / np.sqrt(datasets['background'].value)\n",
    "        \n",
    "        # Excess Rates\n",
    "        SIM_exc_rate = datasets['excess_rate'].value\n",
    "        SIM_exc_erro = SIM_cnt_erro + SIM_bkg_erro\n",
    "        \n",
    "        # Predicted Signal Rates\n",
    "        SIM_exc_pred = datasets['npred_signal'].value / SIM_time_wid     \n",
    "    \n",
    "    ###################################################################\n",
    "    # Define pyplot Figure and Axes\n",
    "    fig, axs = plt.subplots(3,\n",
    "                            figsize = figsize,\n",
    "                            gridspec_kw = {'height_ratios': [2.5, 2.5, 1]}\n",
    "                           )\n",
    "    \n",
    "    # DATA PLOT\n",
    "    \n",
    "    # Plot Empirical Light Curve Data + Error\n",
    "    axs[0].step(LCe_time_val,\n",
    "                LCe_cnt_rate,\n",
    "                label = 'Observed Count Rates', color = 'C1', where = 'mid'\n",
    "               )\n",
    "    axs[0].bar(x      = LCe_time_val,\n",
    "               height = LCe_cnt_erro * 2.0,\n",
    "               bottom = LCe_cnt_rate - LCe_cnt_erro,\n",
    "               width  = LCe_time_wid,\n",
    "               align  = 'center', color = 'C1', alpha = 0.5\n",
    "              )\n",
    "        \n",
    "    # Plot Simulated Light Curve + Error\n",
    "    axs[0].step(SIM_time_val,\n",
    "                SIM_cnt_rate,\n",
    "                label = 'Simulated Count Rates', color = 'C0', where = 'mid'\n",
    "               )\n",
    "    axs[0].bar(x      = SIM_time_val,\n",
    "               height = SIM_cnt_erro * 2.0,\n",
    "               bottom = SIM_cnt_rate - SIM_cnt_erro,\n",
    "               width  = SIM_time_wid,\n",
    "               align  = 'center', color = 'C0', alpha = 0.5\n",
    "              )\n",
    "    \n",
    "    # EXCESS PLOT\n",
    "    \n",
    "    # Plot GBM Excess rates   \n",
    "    axs[1].step(LCe_time_val,\n",
    "                LCe_exc_rate,\n",
    "                label = 'Observed Excess rates', color = 'C1', where = 'mid'\n",
    "               )\n",
    "    axs[1].bar(x = LCe_time_val,\n",
    "               height = LCe_exc_erro * 2.0,\n",
    "               bottom = LCe_exc_rate - LCe_exc_erro,\n",
    "               width  = LCe_time_wid,\n",
    "               align  = 'center', color = 'C1', alpha = 0.5\n",
    "              )\n",
    "        \n",
    "    # Plot GBM excess prediction: Best fit model\n",
    "    axs[1].plot(LCe_time_val,\n",
    "                LCe_exc_pred,\n",
    "                label = 'Best Fit Model Excess', color = 'C3'\n",
    "               )\n",
    "        \n",
    "    # Plot Simulated Exccess rates\n",
    "    axs[1].step(SIM_time_val,\n",
    "                SIM_exc_rate,\n",
    "                label = 'Simulated Excess rates', color = 'C0', where = 'mid'\n",
    "               )\n",
    "    axs[1].bar(x = SIM_time_val,\n",
    "               height = SIM_exc_erro * 2.0,\n",
    "               bottom = SIM_exc_rate - SIM_exc_erro,\n",
    "               width  = SIM_time_wid,\n",
    "               align  = 'center', color = 'C0', alpha = 0.5\n",
    "              )\n",
    "                \n",
    "    # Plot Predicted Rate (Gammapy model through IRFs)\n",
    "    axs[1].plot(SIM_time_val,\n",
    "                SIM_exc_pred,\n",
    "                label = 'Gammapy Model Predicted Excess', color = 'b'\n",
    "               )\n",
    "        \n",
    "    # BACKGROUND ZOOM    \n",
    "    \n",
    "    # Plot GBM Background + Error\n",
    "    axs[2].step(LCe_time_val,\n",
    "                LCe_bkg_rate,\n",
    "                label = 'Observed bkgd rates', color = 'C3', where = 'mid'\n",
    "               )\n",
    "    axs[2].bar(x      = LCe_time_val,\n",
    "               height = LCe_bkg_erro * 2.0,\n",
    "               bottom = LCe_bkg_rate - LCe_bkg_erro,\n",
    "               width  = LCe_time_wid,\n",
    "               align  = 'center', color = 'C3', alpha = 0.5\n",
    "              )\n",
    "    \n",
    "    # Plot Predicted Background    \n",
    "    axs[2].hlines(y = AVG_bkg_pred,\n",
    "                  xmin = SIM_time_val[0],\n",
    "                  xmax = SIM_time_val[-1],\n",
    "                  linewidth = 2, color = 'b', label = 'Gammapy predicted background'\n",
    "                 )    \n",
    "    \n",
    "    # LABELS\n",
    "    axs[0].set_xlabel(\"Time since Trigger [\"+Time_unit.to_string()+\"]\", fontsize = 'large')\n",
    "    axs[1].set_xlabel(\"Time since Trigger [\"+Time_unit.to_string()+\"]\", fontsize = 'large')\n",
    "    axs[2].set_xlabel(\"Time since Trigger [\"+Time_unit.to_string()+\"]\", fontsize = 'large')\n",
    "    axs[0].set_ylabel('Count rates [cts/s]', fontsize = 'large')\n",
    "    axs[1].set_ylabel('Excess Count rates [cts/s]', fontsize = 'large')\n",
    "    axs[2].set_ylabel('Background Count rates [cts/s]', fontsize = 'large')\n",
    "    \n",
    "    axs[0].set_xlim(SIM_time_val[0], SIM_time_val[-1])\n",
    "    axs[1].set_xlim(SIM_time_val[0], SIM_time_val[-1])\n",
    "    axs[2].set_xlim(SIM_time_val[0], SIM_time_val[-1])\n",
    "    \n",
    "    # TITLE PLOT\n",
    "    if avg:\n",
    "        plot_title = f'Average of {Number_of_LightCurves} simulated light curves. '\n",
    "        \n",
    "    else:\n",
    "        plot_title = f'Lightcurve simulation {curve_index+1}/{Number_of_LightCurves}. '\n",
    "        \n",
    "    plot_title += Name_transient+\", \" + Name_instrument+' '+ Name_detector +'.'\n",
    "    \n",
    "    axs[0].set_title(plot_title, fontsize = 'large')\n",
    "    axs[1].set_title(plot_title, fontsize = 'large')\n",
    "    axs[2].set_title(plot_title, fontsize = 'large')\n",
    "    \n",
    "    # OTHER    \n",
    "    axs[0].grid()\n",
    "    axs[1].grid()\n",
    "    axs[2].grid()\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    axs[2].legend()\n",
    "    \n",
    "    if save_figures_directory is not None:\n",
    "        if avg:\n",
    "            save_figures_filename = save_figures_directory + \"lightcurve_avg\"\n",
    "        else:\n",
    "            save_figures_filename = save_figures_directory + \"lightcurve_\"+f\"{curve_index:02d}\"\n",
    "        \n",
    "        extents = [ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted()) for ax in axs]\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \"_all_plots.png\",\n",
    "                    facecolor = 'white'\n",
    "                   )\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \"_count_rates.png\",\n",
    "                    facecolor = 'white',\n",
    "                    bbox_inches = extents[0].expanded(1.2, 1.15)\n",
    "                   )\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \"_excess_rates.png\",\n",
    "                    facecolor = 'white',\n",
    "                    bbox_inches = extents[1].expanded(1.2, 1.15)\n",
    "                   )\n",
    "        \n",
    "        fig.savefig(save_figures_filename + \"_backgrounds_rates.png\",\n",
    "                    facecolor = 'white',\n",
    "                    bbox_inches = extents[2].expanded(1.2, 1.35)\n",
    "                   )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b5c77",
   "metadata": {},
   "source": [
    "Plot the averaged light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b9592",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_light_curve(avg = True,\n",
    "                 figsize = (15.0, 24.0),\n",
    "                 #save_figures_directory = output_directory\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182caab",
   "metadata": {},
   "source": [
    "Choose one light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e46e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_light_curve(avg = False,\n",
    "                 curve_index = 0,\n",
    "                 figsize = (15.0, 24.0),\n",
    "                 #save_figures_directory = output_directory\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548b8bf",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_list = []\n",
    "hdu_list.append(fits.PrimaryHDU())\n",
    "\n",
    "qtable = QTable(datasets_generic.info_table())\n",
    "hdu_list.append(fits.table_to_hdu(qtable))\n",
    "\n",
    "for i_LC in range(Number_of_LightCurves):\n",
    "    qtable = QTable(List_of_Datasets[i_LC].info_table())\n",
    "    hdu_list.append(fits.table_to_hdu(qtable))\n",
    "    \n",
    "hdu_list = fits.HDUList(hdu_list)\n",
    "\n",
    "hdu_list.writeto(output_directory+\"lightcurves.fits\", overwrite=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_light_curve(avg = True,\n",
    "                 figsize = (15.0, 24.0),\n",
    "                 save_figures_directory = output_directory\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_light_curve(avg = False,\n",
    "                 curve_index = 0,\n",
    "                 figsize = (15.0, 24.0),\n",
    "                 save_figures_directory = output_directory\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312fb01",
   "metadata": {},
   "source": [
    "# Flux Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = List_of_Datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the Temporal Model, attach only the Spectral Model to all SpectrumDataset objects\n",
    "# datasets.models = SkyModel(spectral_model = spectral_model, name = \"model-fit\")\n",
    "# datasets.models.to_parameters_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Estimate a Flux Points light curve, each point is the flux of an observation\n",
    "# # The estimator fits the norm of the source model component to datasets in each time interval GTI.\n",
    "# #%%time\n",
    "# lc_maker_1d = LightCurveEstimator(energy_edges = [axis_energy_true.edges[0], axis_energy_true.edges[-1]],#OR RECO?\n",
    "#                                   source = \"model-fit\",\n",
    "#                                   selection_optional = [\"ul\"]\n",
    "#                                  )\n",
    "# # \"all\": all the optional steps are executed\n",
    "# # \"errn-errp\": estimate asymmetric errors.\n",
    "# # \"ul\": estimate upper limits.\n",
    "# # \"scan\": estimate fit statistic profiles.\n",
    "\n",
    "# lc_1d = lc_maker_1d.run(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880adfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = lc_1d.plot(sed_type = \"flux\",  # \"dnde\", flux, eflux, e2dnde\n",
    "#                 energy_power = 1.0, # Power of energy to multiply flux axis with\n",
    "#                 marker = \"o\",\n",
    "#                 label = \"Simulated_LC\")\n",
    "\n",
    "# pl_start = ref_t0 - 0.3 * u.s\n",
    "# pl_end   = ref_t0 + 0.8 * u.s\n",
    "# #ax.set_xlim(pl_start.plot_date, pl_end.plot_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d7211",
   "metadata": {},
   "source": [
    "# Stacked Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = List_of_Datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c69cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the Datasets into one Spectrum Dataset\n",
    "# Stacked_spectrum_dataset = datasets.stack_reduce(name = 'Stacked_sim_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8646ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, figsize = (7,5))\n",
    "# Stacked_spectrum_dataset.plot_counts(ax=ax)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_title('Spectrum time-integrated (stacked)')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b270e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fb32c82",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gammapy.modeling.models import TemplateNPredModel\n",
    "\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].model\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].parameter_norm_only_changed\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].methods_sequence\n",
    "\n",
    "# if dataset_generic.evaluators['Compt-TwoPulse'].model.spatial_model:\n",
    "#     print('spatial model: true')\n",
    "# else: print('spatial model: false')\n",
    "    \n",
    "# print('psf_containment: ',dataset_generic.evaluators['Compt-TwoPulse'].psf_containment)\n",
    "\n",
    "# flux = dataset_generic.evaluators['Compt-TwoPulse'].compute_flux()\n",
    "\n",
    "# flux_expo = dataset_generic.evaluators['Compt-TwoPulse'].apply_exposure(flux)\n",
    "# flux_expo_edisp = dataset_generic.evaluators['Compt-TwoPulse'].apply_edisp(flux_expo)\n",
    "# dataset_generic.evaluators['Compt-TwoPulse'].edisp\n",
    "\n",
    "\n",
    "# #print(temporal_model)\n",
    "# #dataset_generic.npred_signal(model_name='Compt-TwoPulse')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8796459acf233d0db4b2e0e7d5a602f40cefbe1ea4304f822add53168734c030"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
